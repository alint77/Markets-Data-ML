{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.utils as utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "import ta \n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1118"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "csvFileAddress = input('csv file address') \n",
    "\n",
    "DJ = pd.read_csv(csvFileAddress,delim_whitespace=True)\n",
    "\n",
    "DJ['<ISGREEN>'] =  DJ['<CLOSE>'] > DJ['<OPEN>']\n",
    "DJ['<SIZE>'] =  (DJ['<CLOSE>'] - DJ['<OPEN>']) / DJ['<CLOSE>']\n",
    "DJ['<VOLATILITY>'] =  DJ['<HIGH>'] - DJ['<LOW>'] /DJ['<CLOSE>']\n",
    "\n",
    "DJ.drop(['<VOL>'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "timeFrame = (int(DJ.iloc[1][1][1])-int(DJ.iloc[0][1][1]) ) * 60 + (int(DJ.iloc[1][1][3:5])-int(DJ.iloc[0][1][3:5]))\n",
    "CandlesInDay = 24 * (60//timeFrame)\n",
    "timeFrame\n",
    "def candleToTime(j):\n",
    "    minuteMult = CandlesInDay//24\n",
    "    k=j//minuteMult\n",
    "    sth=timeFrame*(j%minuteMult)\n",
    "    return '{:02d}:{:02d}:00'.format(k,sth)\n",
    "\n",
    "uniqueDays = DJ.drop_duplicates(subset='<DATE>')\n",
    "uniqueDays = pd.DataFrame(uniqueDays)\n",
    "\n",
    "uniqueDaysCount=uniqueDays.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "newnumparr = np.full((uniqueDaysCount*CandlesInDay,2),'',dtype=np.object_)\n",
    "\n",
    "\n",
    "for i in range(uniqueDaysCount):\n",
    "    for j in range(CandlesInDay):\n",
    "        newnumparr[(i*CandlesInDay)+j]=[uniqueDays.iloc[i][0],candleToTime(j)]\n",
    "\n",
    "newDF = pd.DataFrame(newnumparr,columns=['<DATE>','<TIME>'])\n",
    "\n",
    "newestDF = newDF.merge(DJ,on=['<DATE>','<TIME>'],how='left')\n",
    "\n",
    "# newestDF.drop(columns=['<OPEN>_x','<CLOSE>_x','<SIZE>_x','<VOLATILITY>_x','<ISGREEN>_x'],inplace=True)\n",
    "newestDF.fillna(0,inplace=True)\n",
    "\n",
    "newestDF['<EMA30>']= ta.trend.ema_indicator( newestDF['<CLOSE>'],window=30)\n",
    "newestDF['<EMA50>']= ta.trend.ema_indicator( newestDF['<CLOSE>'],window=50)\n",
    "newestDF['<EMA200>']= ta.trend.ema_indicator( newestDF['<CLOSE>'],window=200)\n",
    "\n",
    "def Upper(e):\n",
    "    if e['<ISGREEN>'] : \n",
    "        return e['<HIGH>']-e['<CLOSE>']\n",
    "    return e['<HIGH>']-e['<OPEN>']\n",
    "\n",
    "def Lower(e):\n",
    "    if e['<ISGREEN>'] : \n",
    "        return e['<OPEN>']-e['<LOW>']\n",
    "    return e['<CLOSE>']-e['<LOW>']\n",
    "\n",
    "\n",
    "newestDF['<UPPER>'] = newestDF.apply(Upper,axis=1)\n",
    "newestDF['<LOWER>'] = newestDF.apply(Lower,axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# (newestDF,open=\"<OPEN>\",close='<CLOSE>',high='<HIGH>',low='<LOW>',volume='<TICKVOL>',)\n",
    "uniqueDaysCount\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Adding TA indicators : \n",
    "\n",
    "from ta.volatility import BollingerBands,KeltnerChannel,average_true_range\n",
    "from ta.trend import MACD\n",
    "\n",
    "newestDF['<RSI>'] = ta.momentum.rsi(newestDF['<CLOSE>'],window=15,fillna=1) / 100\n",
    "# newestDF['<CCI>'] = ta.trend.cci(close=newestDF['<CLOSE>'],high=newestDF['<HIGH>'],low=newestDF['<LOW>'],window=14,fillna=1)\n",
    "\n",
    "\n",
    "keltner = KeltnerChannel(close=newestDF['<CLOSE>'],high=newestDF['<HIGH>'],low=newestDF['<LOW>'],window=20,window_atr=10,multiplier=2.5,fillna=1)\n",
    "newestDF['<KELTNER_H>'] = keltner.keltner_channel_hband()\n",
    "newestDF['<KELTNER_L>'] = keltner.keltner_channel_lband()\n",
    "newestDF['<KELTNER_M>'] = keltner.keltner_channel_mband()\n",
    "\n",
    "newestDF['<KELT_L_IND>'] = keltner.keltner_channel_lband_indicator()\n",
    "newestDF['<KELT_H_IND>'] = keltner.keltner_channel_hband_indicator()\n",
    "\n",
    "\n",
    "\n",
    "bollinger =BollingerBands(close=newestDF['<CLOSE>'],window=20,window_dev=2.5,fillna=True)\n",
    "newestDF['<BOL_H_IND>']=bollinger.bollinger_hband_indicator()\n",
    "newestDF['<BOL_L_IND>']=bollinger.bollinger_lband_indicator()\n",
    "\n",
    "# macd = MACD(newestDF['<CLOSE>'],fillna=True)\n",
    "\n",
    "\n",
    "newestDF['<ATR_24>'] = average_true_range(close=newestDF['<CLOSE>'],high=newestDF['<HIGH>'],low=newestDF['<LOW>'],window=30).apply(lambda e : e/100)\n",
    "\n",
    "\n",
    "newestDF[\"<GREEN>\"] = newestDF[\"<ISGREEN>\"].astype(int)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;DATE&gt;</th>\n",
       "      <th>&lt;TIME&gt;</th>\n",
       "      <th>&lt;OPEN&gt;</th>\n",
       "      <th>&lt;HIGH&gt;</th>\n",
       "      <th>&lt;LOW&gt;</th>\n",
       "      <th>&lt;CLOSE&gt;</th>\n",
       "      <th>&lt;TICKVOL&gt;</th>\n",
       "      <th>&lt;SPREAD&gt;</th>\n",
       "      <th>&lt;ISGREEN&gt;</th>\n",
       "      <th>&lt;SIZE&gt;</th>\n",
       "      <th>...</th>\n",
       "      <th>&lt;CCI&gt;</th>\n",
       "      <th>&lt;KELTNER_H&gt;</th>\n",
       "      <th>&lt;KELTNER_L&gt;</th>\n",
       "      <th>&lt;KELTNER_M&gt;</th>\n",
       "      <th>&lt;ATR_24&gt;</th>\n",
       "      <th>&lt;GREEN&gt;</th>\n",
       "      <th>&lt;KELT_L_IND&gt;</th>\n",
       "      <th>&lt;KELT_H_IND&gt;</th>\n",
       "      <th>&lt;BOL_H_IND&gt;</th>\n",
       "      <th>&lt;BOL_L_IND&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.01.22</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018.01.22</td>\n",
       "      <td>00:05:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018.01.22</td>\n",
       "      <td>00:10:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018.01.22</td>\n",
       "      <td>00:15:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018.01.22</td>\n",
       "      <td>00:20:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       <DATE>    <TIME>  <OPEN>  <HIGH>  <LOW>  <CLOSE>  <TICKVOL>  <SPREAD>  \\\n",
       "0  2018.01.22  00:00:00     0.0     0.0    0.0      0.0        0.0       0.0   \n",
       "1  2018.01.22  00:05:00     0.0     0.0    0.0      0.0        0.0       0.0   \n",
       "2  2018.01.22  00:10:00     0.0     0.0    0.0      0.0        0.0       0.0   \n",
       "3  2018.01.22  00:15:00     0.0     0.0    0.0      0.0        0.0       0.0   \n",
       "4  2018.01.22  00:20:00     0.0     0.0    0.0      0.0        0.0       0.0   \n",
       "\n",
       "  <ISGREEN>  <SIZE>  ...  <CCI>  <KELTNER_H>  <KELTNER_L>  <KELTNER_M>  \\\n",
       "0         0     0.0  ...    0.0          0.0          0.0          0.0   \n",
       "1         0     0.0  ...    0.0          0.0          0.0          0.0   \n",
       "2         0     0.0  ...    0.0          0.0          0.0          0.0   \n",
       "3         0     0.0  ...    0.0          0.0          0.0          0.0   \n",
       "4         0     0.0  ...    0.0          0.0          0.0          0.0   \n",
       "\n",
       "   <ATR_24>  <GREEN>  <KELT_L_IND>  <KELT_H_IND>  <BOL_H_IND>  <BOL_L_IND>  \n",
       "0       0.0        0           0.0           0.0          0.0          0.0  \n",
       "1       0.0        0           0.0           0.0          0.0          0.0  \n",
       "2       0.0        0           0.0           0.0          0.0          0.0  \n",
       "3       0.0        0           0.0           0.0          0.0          0.0  \n",
       "4       0.0        0           0.0           0.0          0.0          0.0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newestDF.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# input_close = closingPriceOnly =  newestDF[['<CLOSE>']].iloc[:-24].to_numpy()\n",
    "# target_close = closingPriceOnly = newestDF[['<CLOSE>']].iloc[17:].to_numpy()\n",
    "\n",
    "# dataset = utils.timeseries_dataset_from_array(input_close,targets= target_close,sequence_length=17,sequence_stride=24,batch_size=32,)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(list(dataset.as_numpy_iterator()),dtype=object).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeFrame = (int(newestDF.iloc[1]['<TIME>'][1])-int(newestDF.iloc[0]['<TIME>'][1]) ) * 60 + (int(newestDF.iloc[1]['<TIME>'][3:5])-int(newestDF.iloc[0]['<TIME>'][3:5]))\n",
    "CandlesInDay = 24 * (60//timeFrame)\n",
    "uniqueDaysCount = len(newestDF)//CandlesInDay\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "startCandleHour = 8\n",
    "startCandleIndex = int(startCandleHour * CandlesInDay )// 24\n",
    "\n",
    "windowLengthHour = 2.25\n",
    "windowLengthCount = int(windowLengthHour * CandlesInDay) // 24\n",
    "\n",
    "\n",
    "labelStartCandleHour = startCandleHour+windowLengthHour\n",
    "labelStartCandleIndex = int(labelStartCandleHour * CandlesInDay) // 24\n",
    "\n",
    "labelWindowLengthHour = 1\n",
    "labelWindowLengthCount = int(labelWindowLengthHour * CandlesInDay) // 24\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "takeProfitPoints = 1.002\n",
    "stopLoss = .998\n",
    "PriceOnly = newestDF.drop(['<DATE>','<TIME>'],axis=1)\n",
    "PriceOnly\n",
    "windows = []\n",
    "labelsDFs = []\n",
    "labelValues = []\n",
    "df = PriceOnly\n",
    "\n",
    "maxValues = df.max()\n",
    "\n",
    "for i in range(0,len(df)-CandlesInDay , CandlesInDay):\n",
    "    trainDF = df.iloc[i+startCandleIndex : (i+startCandleIndex +windowLengthCount)]\n",
    "    labelDF = df.iloc[i+labelStartCandleIndex :(i+labelStartCandleIndex+labelWindowLengthCount) ]\n",
    "\n",
    "    lowestIndex = labelDF['<LOW>'].idxmin()\n",
    "    lowestPriceInLabels = labelDF['<LOW>'][lowestIndex]\n",
    "\n",
    "    highesIndex = labelDF['<HIGH>'].idxmax()\n",
    "    highestPriceInLabels = labelDF['<HIGH>'][highesIndex]\n",
    "\n",
    "    TP = labelDF['<OPEN>'].iloc[0]*takeProfitPoints\n",
    "    SL = labelDF['<OPEN>'].iloc[0]*stopLoss\n",
    "\n",
    "    buySignal = 0\n",
    "\n",
    "    if highestPriceInLabels < TP and lowestPriceInLabels > SL:\n",
    "        # ideas : halfTP\n",
    "        buySignal=2\n",
    "        \n",
    "    elif highestPriceInLabels < TP and lowestPriceInLabels < SL:\n",
    "        buySignal = 0\n",
    "    elif highestPriceInLabels > TP and lowestPriceInLabels > SL:\n",
    "        buySignal = 1\n",
    "    else :\n",
    "        tpIndex = 0\n",
    "        slIndex = 0\n",
    "        for j in range(len(labelDF)):\n",
    "            if labelDF['<HIGH>'].iloc[j] > TP and labelDF['<LOW>'].iloc[j]>SL :\n",
    "                tpIndex=j\n",
    "            if labelDF['<HIGH>'].iloc[j] < TP and labelDF['<LOW>'].iloc[j]>SL :\n",
    "                continue\n",
    "            if labelDF['<HIGH>'].iloc[j] < TP and labelDF['<LOW>'].iloc[j]<SL :\n",
    "                slIndex=j\n",
    "        buySignal = int(tpIndex<slIndex)\n",
    "        if slIndex==tpIndex:\n",
    "            continue\n",
    "    \n",
    "\n",
    "    # trainDF =  trainDF /df.abs().max()\n",
    "    trainDF=(trainDF-df.min())/(df.max()-df.min())\n",
    "\n",
    "    # trainDF = trainDF.drop(['<OPEN>','<ATR_24>','<EMA30>','<RSI>','<CCI>','<KELTNER_M>','<KELTNER_L>','<KELTNER_H>','<GREEN>'],axis=1)\n",
    "    trainDF = trainDF[['<SIZE>','<UPPER>','<LOWER>','<TICKVOL>','<KELT_L_IND>','<KELT_H_IND>','<BOL_L_IND>','<BOL_H_IND>']]\n",
    "\n",
    "\n",
    "    trainNp =(trainDF.to_numpy(dtype=np.float32))\n",
    "    # trainNp = np.rot90( trainDF.to_numpy())\n",
    "\n",
    "\n",
    "    labelValues.append(buySignal)\n",
    "    windows.append(trainNp)\n",
    "    labelsDFs.append(labelDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "signal\n",
       "0         0.478533\n",
       "1         0.462433\n",
       "2         0.058140\n",
       "dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(labelValues,columns=['signal']).value_counts()/uniqueDaysCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.522355</td>\n",
       "      <td>0.008734</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.514744</td>\n",
       "      <td>0.013100</td>\n",
       "      <td>0.004907</td>\n",
       "      <td>0.033291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.513220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.516266</td>\n",
       "      <td>0.004367</td>\n",
       "      <td>0.004907</td>\n",
       "      <td>0.032864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.513218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004907</td>\n",
       "      <td>0.052070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.519311</td>\n",
       "      <td>0.004367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.516264</td>\n",
       "      <td>0.004367</td>\n",
       "      <td>0.019627</td>\n",
       "      <td>0.039693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.514740</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.519311</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009814</td>\n",
       "      <td>0.024755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.517787</td>\n",
       "      <td>0.017467</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.514739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004907</td>\n",
       "      <td>0.052924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.516263</td>\n",
       "      <td>0.004367</td>\n",
       "      <td>0.039254</td>\n",
       "      <td>0.113956</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.514737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014720</td>\n",
       "      <td>0.061033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.513211</td>\n",
       "      <td>0.017467</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.514735</td>\n",
       "      <td>0.008734</td>\n",
       "      <td>0.009814</td>\n",
       "      <td>0.075544</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.522362</td>\n",
       "      <td>0.013100</td>\n",
       "      <td>0.004907</td>\n",
       "      <td>0.082800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.513208</td>\n",
       "      <td>0.026201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.516259</td>\n",
       "      <td>0.017467</td>\n",
       "      <td>0.024534</td>\n",
       "      <td>0.082373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.500984</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014720</td>\n",
       "      <td>0.118651</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.494847</td>\n",
       "      <td>0.004367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.126334</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.534589</td>\n",
       "      <td>0.013100</td>\n",
       "      <td>0.014720</td>\n",
       "      <td>0.141699</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.499431</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044161</td>\n",
       "      <td>0.170721</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.534593</td>\n",
       "      <td>0.004367</td>\n",
       "      <td>0.039254</td>\n",
       "      <td>0.205292</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.542210</td>\n",
       "      <td>0.008734</td>\n",
       "      <td>0.093229</td>\n",
       "      <td>0.571490</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.548277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068695</td>\n",
       "      <td>0.482288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.542155</td>\n",
       "      <td>0.021834</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.374306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3    4    5    6    7\n",
       "0   0.522355  0.008734  0.000000  0.030303  0.0  1.0  0.0  1.0\n",
       "1   0.520833  0.000000  0.000000  0.014938  0.0  1.0  0.0  1.0\n",
       "2   0.514744  0.013100  0.004907  0.033291  0.0  1.0  0.0  0.0\n",
       "3   0.513220  0.000000  0.000000  0.040120  0.0  1.0  0.0  0.0\n",
       "4   0.516266  0.004367  0.004907  0.032864  0.0  1.0  0.0  0.0\n",
       "5   0.513218  0.000000  0.004907  0.052070  0.0  1.0  0.0  0.0\n",
       "6   0.519311  0.004367  0.000000  0.013231  0.0  1.0  0.0  0.0\n",
       "7   0.516264  0.004367  0.019627  0.039693  0.0  1.0  0.0  0.0\n",
       "8   0.514740  0.000000  0.000000  0.029023  0.0  1.0  0.0  0.0\n",
       "9   0.519311  0.000000  0.009814  0.024755  0.0  1.0  0.0  0.0\n",
       "10  0.517787  0.017467  0.000000  0.038412  0.0  1.0  0.0  0.0\n",
       "11  0.514739  0.000000  0.004907  0.052924  0.0  1.0  0.0  0.0\n",
       "12  0.516263  0.004367  0.039254  0.113956  0.0  1.0  0.0  0.0\n",
       "13  0.514737  0.000000  0.014720  0.061033  0.0  1.0  0.0  0.0\n",
       "14  0.513211  0.017467  0.000000  0.075971  0.0  1.0  0.0  0.0\n",
       "15  0.514735  0.008734  0.009814  0.075544  0.0  1.0  0.0  0.0\n",
       "16  0.522362  0.013100  0.004907  0.082800  0.0  1.0  0.0  0.0\n",
       "17  0.513208  0.026201  0.000000  0.066155  0.0  1.0  0.0  0.0\n",
       "18  0.516259  0.017467  0.024534  0.082373  0.0  1.0  0.0  0.0\n",
       "19  0.500984  0.000000  0.014720  0.118651  1.0  0.0  0.0  0.0\n",
       "20  0.494847  0.004367  0.000000  0.126334  1.0  0.0  1.0  0.0\n",
       "21  0.534589  0.013100  0.014720  0.141699  1.0  0.0  0.0  0.0\n",
       "22  0.499431  0.000000  0.044161  0.170721  1.0  0.0  0.0  0.0\n",
       "23  0.534593  0.004367  0.039254  0.205292  1.0  0.0  0.0  0.0\n",
       "24  0.542210  0.008734  0.093229  0.571490  0.0  0.0  0.0  0.0\n",
       "25  0.548277  0.000000  0.068695  0.482288  0.0  0.0  0.0  0.0\n",
       "26  0.542155  0.021834  0.000000  0.374306  0.0  1.0  0.0  0.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(windows[43])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "# windows[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1117, 1117, 1118)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labelValues),len(labelsDFs),uniqueDaysCount\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(windows)\n",
    "windows2= np.array(windows)\n",
    "# windows=windows[...,np.newaxis]\n",
    "\n",
    "labelValues = np.array(labelValues)\n",
    "\n",
    "\n",
    "train_data = windows2[:int(l*.75)]\n",
    "val_data = windows2[int(l*.75):]\n",
    "\n",
    "\n",
    "\n",
    "train_labels = labelValues[:int(l*.75)].astype(np.uint8)\n",
    "train_labels_hot = np.eye(3).astype(np.uint8)[train_labels]\n",
    "\n",
    "\n",
    "val_labels = labelValues[int(l*.75):].astype(np.uint8)\n",
    "val_labels_hot = (np.eye(3).astype(np.uint8)[val_labels])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data_rnn = train_data\n",
    "val_data_rnn = val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((837, 27, 8), (837,))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_rnn.shape,train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_26 (Dense)            (None, 27, 50)            450       \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 27, 16)            3264      \n",
      "                                                                 \n",
      " gru_3 (GRU)                 (None, 27, 32)            4800      \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 27, 50)            1650      \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 27, 3)             153       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,317\n",
      "Trainable params: 10,317\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D,LSTM, ConvLSTM1D,Flatten,SimpleRNN,GRU,AveragePooling2D\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model_rnn = keras.Sequential([\n",
    "    Dense(50,activation='relu',input_shape=train_data_rnn[0].shape),\n",
    "    GRU(16,dropout=.1,return_sequences=1),\n",
    "    GRU(32,dropout=.1,return_sequences=1),\n",
    "    # Flatten(),\n",
    "    Dense(50,activation='relu'),\n",
    "    Dense(3,activation='sigmoid'),\n",
    "\n",
    "])\n",
    "\n",
    "model_rnn.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "optimizer = keras.optimizers.Adam(),\n",
    "metrics=['accuracy'])\n",
    "\n",
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rnn.fit(train_data_rnn,train_labels,validation_data=(val_data_rnn,val_labels),epochs=200,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows1=windows2[...,np.newaxis]\n",
    "\n",
    "\n",
    "\n",
    "train_data_cnn = windows1[:int(l*.75)]\n",
    "val_data_cnn = windows1[int(l*.75):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(837, 27, 8, 1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_cnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(50,2,activation='relu',input_shape=train_data[0].shape))\n",
    "model.add(Conv2D(50,2,activation='relu',))\n",
    "model.add(AveragePooling2D(2))\n",
    "model.add(LSTM(24,return_sequences=1,)),\n",
    "model.add(Dropout(.1))\n",
    "model.add(LSTM(32,return_sequences=0)),\n",
    "model.add(Dropout(.1))\n",
    "\n",
    "model.add(Dense(3))\n",
    "\n",
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data_cnn, train_labels,batch_size=64,verbose=2 , epochs = 100,validation_data=(val_data_cnn,val_labels))\n",
    "\n",
    "# model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data, train_labels,batch_size=128,verbose=2 , initial_epoch=15, epochs = 30,validation_data=(val_data,val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(585, 32, 4, 1)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.345085</td>\n",
       "      <td>0.198083</td>\n",
       "      <td>0.174221</td>\n",
       "      <td>0.247059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.306065</td>\n",
       "      <td>0.073482</td>\n",
       "      <td>0.059490</td>\n",
       "      <td>0.182353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.375746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.375746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.375746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.375746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.375746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.310232</td>\n",
       "      <td>0.011182</td>\n",
       "      <td>0.143059</td>\n",
       "      <td>0.110240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.478205</td>\n",
       "      <td>0.028754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.165251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.333600</td>\n",
       "      <td>0.049521</td>\n",
       "      <td>0.032578</td>\n",
       "      <td>0.155991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.196083</td>\n",
       "      <td>0.054313</td>\n",
       "      <td>0.016997</td>\n",
       "      <td>0.156972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.379737</td>\n",
       "      <td>0.230032</td>\n",
       "      <td>0.155807</td>\n",
       "      <td>0.211656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.422896</td>\n",
       "      <td>0.014377</td>\n",
       "      <td>0.228045</td>\n",
       "      <td>0.198366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.300855</td>\n",
       "      <td>0.075080</td>\n",
       "      <td>0.055241</td>\n",
       "      <td>0.151525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.295173</td>\n",
       "      <td>0.051118</td>\n",
       "      <td>0.067989</td>\n",
       "      <td>0.130501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.372293</td>\n",
       "      <td>0.130990</td>\n",
       "      <td>0.035411</td>\n",
       "      <td>0.131590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.521840</td>\n",
       "      <td>0.134185</td>\n",
       "      <td>0.029745</td>\n",
       "      <td>0.136710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.716397</td>\n",
       "      <td>0.020767</td>\n",
       "      <td>0.041076</td>\n",
       "      <td>0.373203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.504749</td>\n",
       "      <td>0.498403</td>\n",
       "      <td>0.011331</td>\n",
       "      <td>0.469063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.360410</td>\n",
       "      <td>0.571885</td>\n",
       "      <td>0.070822</td>\n",
       "      <td>0.360893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.349953</td>\n",
       "      <td>0.022364</td>\n",
       "      <td>0.461756</td>\n",
       "      <td>0.317320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.440161</td>\n",
       "      <td>0.012780</td>\n",
       "      <td>0.110482</td>\n",
       "      <td>0.211002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.521459</td>\n",
       "      <td>0.110224</td>\n",
       "      <td>0.203966</td>\n",
       "      <td>0.229085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.431596</td>\n",
       "      <td>0.305112</td>\n",
       "      <td>0.015581</td>\n",
       "      <td>0.246514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.320172</td>\n",
       "      <td>0.322684</td>\n",
       "      <td>0.151558</td>\n",
       "      <td>0.258061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.278929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130312</td>\n",
       "      <td>0.265359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.480925</td>\n",
       "      <td>0.108626</td>\n",
       "      <td>0.116147</td>\n",
       "      <td>0.234858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.478929</td>\n",
       "      <td>0.007987</td>\n",
       "      <td>0.063739</td>\n",
       "      <td>0.122331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.315559</td>\n",
       "      <td>0.023962</td>\n",
       "      <td>0.079320</td>\n",
       "      <td>0.146623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.420170</td>\n",
       "      <td>0.011182</td>\n",
       "      <td>0.094901</td>\n",
       "      <td>0.123312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.500770</td>\n",
       "      <td>0.028754</td>\n",
       "      <td>0.031161</td>\n",
       "      <td>0.079739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.375746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3\n",
       "0   0.345085  0.198083  0.174221  0.247059\n",
       "1   0.306065  0.073482  0.059490  0.182353\n",
       "2   0.375746  0.000000  0.000000  0.000000\n",
       "3   0.375746  0.000000  0.000000  0.000000\n",
       "4   0.375746  0.000000  0.000000  0.000000\n",
       "5   0.375746  0.000000  0.000000  0.000000\n",
       "6   0.375746  0.000000  0.000000  0.000000\n",
       "7   0.310232  0.011182  0.143059  0.110240\n",
       "8   0.478205  0.028754  0.000000  0.165251\n",
       "9   0.333600  0.049521  0.032578  0.155991\n",
       "10  0.196083  0.054313  0.016997  0.156972\n",
       "11  0.379737  0.230032  0.155807  0.211656\n",
       "12  0.422896  0.014377  0.228045  0.198366\n",
       "13  0.300855  0.075080  0.055241  0.151525\n",
       "14  0.295173  0.051118  0.067989  0.130501\n",
       "15  0.372293  0.130990  0.035411  0.131590\n",
       "16  0.521840  0.134185  0.029745  0.136710\n",
       "17  0.716397  0.020767  0.041076  0.373203\n",
       "18  0.504749  0.498403  0.011331  0.469063\n",
       "19  0.360410  0.571885  0.070822  0.360893\n",
       "20  0.349953  0.022364  0.461756  0.317320\n",
       "21  0.440161  0.012780  0.110482  0.211002\n",
       "22  0.521459  0.110224  0.203966  0.229085\n",
       "23  0.431596  0.305112  0.015581  0.246514\n",
       "24  0.320172  0.322684  0.151558  0.258061\n",
       "25  0.278929  0.000000  0.130312  0.265359\n",
       "26  0.480925  0.108626  0.116147  0.234858\n",
       "27  0.478929  0.007987  0.063739  0.122331\n",
       "28  0.315559  0.023962  0.079320  0.146623\n",
       "29  0.420170  0.011182  0.094901  0.123312\n",
       "30  0.500770  0.028754  0.031161  0.079739\n",
       "31  0.375746  0.000000  0.000000  0.000109"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.squeeze(train_data[232]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_labels[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_18 (Conv2D)          (None, 28, 3, 32)         352       \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 24, 2, 32)         10272     \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 20, 1, 32)         10272     \n",
      "                                                                 \n",
      " flatten_25 (Flatten)        (None, 640)               0         \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 3)                 1923      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,819\n",
      "Trainable params: 22,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model_1 = tf.keras.Sequential([\n",
    "    keras.layers.Conv2D(32,(5,2) , input_shape=train_data[0].shape,activation='relu'),\n",
    "    keras.layers.Conv2D(32,(5,2) ,activation='relu'),\n",
    "    keras.layers.Conv2D(32,(5,2) ,activation='relu'),\n",
    "\n",
    " \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(3 ,activation='softmax' ),\n",
    "])\n",
    "model_1.compile(\n",
    "    loss = tf.keras.losses.sparse_categorical_crossentropy,\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "model_1.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "585/585 - 4s - loss: 1.0849 - accuracy: 0.3590 - val_loss: 1.1960 - val_accuracy: 0.3436 - 4s/epoch - 6ms/step\n",
      "Epoch 2/250\n",
      "585/585 - 3s - loss: 1.0347 - accuracy: 0.4325 - val_loss: 1.2065 - val_accuracy: 0.3846 - 3s/epoch - 5ms/step\n",
      "Epoch 3/250\n",
      "585/585 - 3s - loss: 0.9637 - accuracy: 0.5111 - val_loss: 1.0973 - val_accuracy: 0.5538 - 3s/epoch - 5ms/step\n",
      "Epoch 4/250\n",
      "585/585 - 3s - loss: 0.9664 - accuracy: 0.4923 - val_loss: 1.2128 - val_accuracy: 0.4000 - 3s/epoch - 5ms/step\n",
      "Epoch 5/250\n",
      "585/585 - 3s - loss: 0.9543 - accuracy: 0.4872 - val_loss: 1.2458 - val_accuracy: 0.4000 - 3s/epoch - 5ms/step\n",
      "Epoch 6/250\n",
      "585/585 - 3s - loss: 0.9461 - accuracy: 0.5111 - val_loss: 1.1070 - val_accuracy: 0.5385 - 3s/epoch - 5ms/step\n",
      "Epoch 7/250\n",
      "585/585 - 3s - loss: 0.9429 - accuracy: 0.5145 - val_loss: 1.1544 - val_accuracy: 0.5436 - 3s/epoch - 5ms/step\n",
      "Epoch 8/250\n",
      "585/585 - 3s - loss: 0.9486 - accuracy: 0.4872 - val_loss: 1.1276 - val_accuracy: 0.3641 - 3s/epoch - 5ms/step\n",
      "Epoch 9/250\n",
      "585/585 - 3s - loss: 0.9343 - accuracy: 0.5043 - val_loss: 1.3347 - val_accuracy: 0.3949 - 3s/epoch - 5ms/step\n",
      "Epoch 10/250\n",
      "585/585 - 3s - loss: 0.9358 - accuracy: 0.5145 - val_loss: 1.2349 - val_accuracy: 0.4974 - 3s/epoch - 5ms/step\n",
      "Epoch 11/250\n",
      "585/585 - 3s - loss: 0.9346 - accuracy: 0.5094 - val_loss: 1.6134 - val_accuracy: 0.3744 - 3s/epoch - 5ms/step\n",
      "Epoch 12/250\n",
      "585/585 - 3s - loss: 0.9293 - accuracy: 0.5179 - val_loss: 1.3150 - val_accuracy: 0.4154 - 3s/epoch - 5ms/step\n",
      "Epoch 13/250\n",
      "585/585 - 3s - loss: 0.9315 - accuracy: 0.4991 - val_loss: 1.6456 - val_accuracy: 0.3846 - 3s/epoch - 5ms/step\n",
      "Epoch 14/250\n",
      "585/585 - 3s - loss: 0.9298 - accuracy: 0.5197 - val_loss: 1.3335 - val_accuracy: 0.4000 - 3s/epoch - 5ms/step\n",
      "Epoch 15/250\n",
      "585/585 - 3s - loss: 0.9244 - accuracy: 0.5248 - val_loss: 1.3861 - val_accuracy: 0.4205 - 3s/epoch - 5ms/step\n",
      "Epoch 16/250\n",
      "585/585 - 3s - loss: 0.9214 - accuracy: 0.5179 - val_loss: 1.4806 - val_accuracy: 0.4667 - 3s/epoch - 5ms/step\n",
      "Epoch 17/250\n",
      "585/585 - 3s - loss: 0.9282 - accuracy: 0.5179 - val_loss: 1.5445 - val_accuracy: 0.4974 - 3s/epoch - 4ms/step\n",
      "Epoch 18/250\n",
      "585/585 - 3s - loss: 0.9289 - accuracy: 0.5214 - val_loss: 1.5630 - val_accuracy: 0.3795 - 3s/epoch - 5ms/step\n",
      "Epoch 19/250\n",
      "585/585 - 3s - loss: 0.9270 - accuracy: 0.5231 - val_loss: 1.5967 - val_accuracy: 0.5179 - 3s/epoch - 5ms/step\n",
      "Epoch 20/250\n",
      "585/585 - 3s - loss: 0.9257 - accuracy: 0.5504 - val_loss: 1.5552 - val_accuracy: 0.3846 - 3s/epoch - 5ms/step\n",
      "Epoch 21/250\n",
      "585/585 - 3s - loss: 0.9211 - accuracy: 0.5179 - val_loss: 1.7228 - val_accuracy: 0.5333 - 3s/epoch - 5ms/step\n",
      "Epoch 22/250\n",
      "585/585 - 3s - loss: 0.9169 - accuracy: 0.5470 - val_loss: 1.6266 - val_accuracy: 0.4821 - 3s/epoch - 5ms/step\n",
      "Epoch 23/250\n",
      "585/585 - 3s - loss: 0.9118 - accuracy: 0.5265 - val_loss: 1.4844 - val_accuracy: 0.5231 - 3s/epoch - 5ms/step\n",
      "Epoch 24/250\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/alint/Desktop/CTFlearn/digi/PyCourse/Cnn.ipynb Cell 24'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/alint/Desktop/CTFlearn/digi/PyCourse/Cnn.ipynb#ch0000021?line=0'>1</a>\u001b[0m model_1_history \u001b[39m=\u001b[39m model_1\u001b[39m.\u001b[39;49mfit( train_data, train_labels,batch_size\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m ,verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,epochs\u001b[39m=\u001b[39;49m\u001b[39m250\u001b[39;49m,validation_data\u001b[39m=\u001b[39;49m(val_data,val_labels),shuffle\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "model_1_history = model_1.fit( train_data, train_labels,batch_size=1 ,verbose=2,epochs=250,validation_data=(val_data,val_labels),shuffle=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_squeeze=np.squeeze(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data=np.squeeze(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(585, 32, 4)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_squeeze.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "585/585 - 4s - loss: 1.0854 - accuracy: 0.3761 - val_loss: 0.9521 - val_accuracy: 0.4205 - 4s/epoch - 6ms/step\n",
      "Epoch 2/200\n",
      "585/585 - 3s - loss: 1.0036 - accuracy: 0.4838 - val_loss: 0.9410 - val_accuracy: 0.3795 - 3s/epoch - 5ms/step\n",
      "Epoch 3/200\n",
      "585/585 - 3s - loss: 0.9677 - accuracy: 0.4940 - val_loss: 0.9477 - val_accuracy: 0.3897 - 3s/epoch - 5ms/step\n",
      "Epoch 4/200\n",
      "585/585 - 3s - loss: 0.9646 - accuracy: 0.4821 - val_loss: 0.9007 - val_accuracy: 0.5385 - 3s/epoch - 5ms/step\n",
      "Epoch 5/200\n",
      "585/585 - 3s - loss: 0.9583 - accuracy: 0.5026 - val_loss: 0.9162 - val_accuracy: 0.5436 - 3s/epoch - 5ms/step\n",
      "Epoch 6/200\n",
      "585/585 - 3s - loss: 0.9550 - accuracy: 0.5060 - val_loss: 0.9249 - val_accuracy: 0.4667 - 3s/epoch - 5ms/step\n",
      "Epoch 7/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/alint/Desktop/CTFlearn/digi/PyCourse/Cnn.ipynb Cell 28'\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alint/Desktop/CTFlearn/digi/PyCourse/Cnn.ipynb#ch0000022?line=15'>16</a>\u001b[0m model_2\u001b[39m.\u001b[39mcompile(loss \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39msparse_categorical_crossentropy,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alint/Desktop/CTFlearn/digi/PyCourse/Cnn.ipynb#ch0000022?line=16'>17</a>\u001b[0m optimizer \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alint/Desktop/CTFlearn/digi/PyCourse/Cnn.ipynb#ch0000022?line=17'>18</a>\u001b[0m metrics \u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alint/Desktop/CTFlearn/digi/PyCourse/Cnn.ipynb#ch0000022?line=18'>19</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alint/Desktop/CTFlearn/digi/PyCourse/Cnn.ipynb#ch0000022?line=20'>21</a>\u001b[0m \u001b[39m# model_2.summary()\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/alint/Desktop/CTFlearn/digi/PyCourse/Cnn.ipynb#ch0000022?line=22'>23</a>\u001b[0m model_2_history \u001b[39m=\u001b[39m model_2\u001b[39m.\u001b[39;49mfit( train_data, train_labels ,batch_size\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m , epochs \u001b[39m=\u001b[39;49m \u001b[39m200\u001b[39;49m,shuffle\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,validation_data\u001b[39m=\u001b[39;49m(val_data,val_labels))\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(14)\n",
    "\n",
    "model_2 = tf.keras.Sequential([\n",
    "\n",
    "    tf.keras.layers.Flatten( input_shape=windows[0].shape),\n",
    "\n",
    "    tf.keras.layers.Dense(50 ,activation='relu' ),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(50 ,activation='relu' ),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    tf.keras.layers.Dense(50 ,activation='relu' ),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(3 ,activation='softmax' ),\n",
    "])\n",
    "model_2.compile(loss = tf.keras.losses.sparse_categorical_crossentropy,\n",
    "optimizer = keras.optimizers.Adam(),\n",
    "metrics =['accuracy']\n",
    ")\n",
    "\n",
    "# model_2.summary()\n",
    "\n",
    "model_2_history = model_2.fit( train_data, train_labels ,batch_size=1,verbose=2 , epochs = 200,shuffle=1,validation_data=(val_data,val_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.010226</td>\n",
       "      <td>0.015974</td>\n",
       "      <td>0.014164</td>\n",
       "      <td>0.037255</td>\n",
       "      <td>0.180084</td>\n",
       "      <td>0.577697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.024867</td>\n",
       "      <td>0.009585</td>\n",
       "      <td>0.001416</td>\n",
       "      <td>0.039542</td>\n",
       "      <td>0.174547</td>\n",
       "      <td>0.570750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.461322</td>\n",
       "      <td>0.053014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.445945</td>\n",
       "      <td>0.053014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.431080</td>\n",
       "      <td>0.053014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.416711</td>\n",
       "      <td>0.053014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.402820</td>\n",
       "      <td>0.053014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.006585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002833</td>\n",
       "      <td>0.008170</td>\n",
       "      <td>0.681964</td>\n",
       "      <td>0.587567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.012447</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>0.026912</td>\n",
       "      <td>0.015904</td>\n",
       "      <td>0.659652</td>\n",
       "      <td>0.587321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.005859</td>\n",
       "      <td>0.006390</td>\n",
       "      <td>0.008499</td>\n",
       "      <td>0.014379</td>\n",
       "      <td>0.637868</td>\n",
       "      <td>0.587218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.009526</td>\n",
       "      <td>0.014377</td>\n",
       "      <td>0.024079</td>\n",
       "      <td>0.030937</td>\n",
       "      <td>0.617049</td>\n",
       "      <td>0.587029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.010264</td>\n",
       "      <td>0.019169</td>\n",
       "      <td>0.015581</td>\n",
       "      <td>0.026362</td>\n",
       "      <td>0.596900</td>\n",
       "      <td>0.586810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.020550</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>0.019830</td>\n",
       "      <td>0.034641</td>\n",
       "      <td>0.577492</td>\n",
       "      <td>0.586288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.006608</td>\n",
       "      <td>0.004792</td>\n",
       "      <td>0.031161</td>\n",
       "      <td>0.034423</td>\n",
       "      <td>0.558628</td>\n",
       "      <td>0.586095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.000734</td>\n",
       "      <td>0.004792</td>\n",
       "      <td>0.019830</td>\n",
       "      <td>0.025599</td>\n",
       "      <td>0.540212</td>\n",
       "      <td>0.586074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.012475</td>\n",
       "      <td>0.028754</td>\n",
       "      <td>0.005666</td>\n",
       "      <td>0.026688</td>\n",
       "      <td>0.522647</td>\n",
       "      <td>0.586327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.002202</td>\n",
       "      <td>0.007987</td>\n",
       "      <td>0.011331</td>\n",
       "      <td>0.022004</td>\n",
       "      <td>0.505407</td>\n",
       "      <td>0.586256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.009585</td>\n",
       "      <td>0.014164</td>\n",
       "      <td>0.017320</td>\n",
       "      <td>0.488765</td>\n",
       "      <td>0.586310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.002202</td>\n",
       "      <td>0.003195</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.013617</td>\n",
       "      <td>0.472586</td>\n",
       "      <td>0.586256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009915</td>\n",
       "      <td>0.013181</td>\n",
       "      <td>0.456935</td>\n",
       "      <td>0.586298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.015422</td>\n",
       "      <td>0.009585</td>\n",
       "      <td>0.012748</td>\n",
       "      <td>0.025599</td>\n",
       "      <td>0.442113</td>\n",
       "      <td>0.585643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.002938</td>\n",
       "      <td>0.011182</td>\n",
       "      <td>0.016997</td>\n",
       "      <td>0.019499</td>\n",
       "      <td>0.427637</td>\n",
       "      <td>0.585543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.022060</td>\n",
       "      <td>0.004792</td>\n",
       "      <td>0.001416</td>\n",
       "      <td>0.028322</td>\n",
       "      <td>0.413768</td>\n",
       "      <td>0.584472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.019875</td>\n",
       "      <td>0.006390</td>\n",
       "      <td>0.002833</td>\n",
       "      <td>0.031373</td>\n",
       "      <td>0.400351</td>\n",
       "      <td>0.583444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.015974</td>\n",
       "      <td>0.042493</td>\n",
       "      <td>0.045098</td>\n",
       "      <td>0.387471</td>\n",
       "      <td>0.583532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.012507</td>\n",
       "      <td>0.019169</td>\n",
       "      <td>0.033994</td>\n",
       "      <td>0.046296</td>\n",
       "      <td>0.375157</td>\n",
       "      <td>0.583910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.017677</td>\n",
       "      <td>0.009585</td>\n",
       "      <td>0.026912</td>\n",
       "      <td>0.044771</td>\n",
       "      <td>0.363208</td>\n",
       "      <td>0.582557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.000737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050992</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.351533</td>\n",
       "      <td>0.582458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.033945</td>\n",
       "      <td>0.003195</td>\n",
       "      <td>0.002833</td>\n",
       "      <td>0.038889</td>\n",
       "      <td>0.340383</td>\n",
       "      <td>0.579958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.018466</td>\n",
       "      <td>0.012780</td>\n",
       "      <td>0.012748</td>\n",
       "      <td>0.037908</td>\n",
       "      <td>0.329513</td>\n",
       "      <td>0.578544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.010336</td>\n",
       "      <td>0.003195</td>\n",
       "      <td>0.050992</td>\n",
       "      <td>0.043246</td>\n",
       "      <td>0.319120</td>\n",
       "      <td>0.579123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.004431</td>\n",
       "      <td>0.022364</td>\n",
       "      <td>0.012748</td>\n",
       "      <td>0.032135</td>\n",
       "      <td>0.308812</td>\n",
       "      <td>0.578670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5\n",
       "0  -0.010226  0.015974  0.014164  0.037255  0.180084  0.577697\n",
       "1  -0.024867  0.009585  0.001416  0.039542  0.174547  0.570750\n",
       "2   0.000000  0.000000  0.000000  0.000000  0.461322  0.053014\n",
       "3   0.000000  0.000000  0.000000  0.000000  0.445945  0.053014\n",
       "4   0.000000  0.000000  0.000000  0.000000  0.431080  0.053014\n",
       "5   0.000000  0.000000  0.000000  0.000000  0.416711  0.053014\n",
       "6   0.000000  0.000000  0.000000  0.000000  0.402820  0.053014\n",
       "7  -0.006585  0.000000  0.002833  0.008170  0.681964  0.587567\n",
       "8  -0.012447  0.001597  0.026912  0.015904  0.659652  0.587321\n",
       "9  -0.005859  0.006390  0.008499  0.014379  0.637868  0.587218\n",
       "10 -0.009526  0.014377  0.024079  0.030937  0.617049  0.587029\n",
       "11 -0.010264  0.019169  0.015581  0.026362  0.596900  0.586810\n",
       "12 -0.020550  0.001597  0.019830  0.034641  0.577492  0.586288\n",
       "13 -0.006608  0.004792  0.031161  0.034423  0.558628  0.586095\n",
       "14 -0.000734  0.004792  0.019830  0.025599  0.540212  0.586074\n",
       "15  0.012475  0.028754  0.005666  0.026688  0.522647  0.586327\n",
       "16 -0.002202  0.007987  0.011331  0.022004  0.505407  0.586256\n",
       "17  0.001468  0.009585  0.014164  0.017320  0.488765  0.586310\n",
       "18 -0.002202  0.003195  0.007082  0.013617  0.472586  0.586256\n",
       "19  0.001468  0.000000  0.009915  0.013181  0.456935  0.586298\n",
       "20 -0.015422  0.009585  0.012748  0.025599  0.442113  0.585643\n",
       "21 -0.002938  0.011182  0.016997  0.019499  0.427637  0.585543\n",
       "22 -0.022060  0.004792  0.001416  0.028322  0.413768  0.584472\n",
       "23 -0.019875  0.006390  0.002833  0.031373  0.400351  0.583444\n",
       "24  0.000736  0.015974  0.042493  0.045098  0.387471  0.583532\n",
       "25  0.012507  0.019169  0.033994  0.046296  0.375157  0.583910\n",
       "26 -0.017677  0.009585  0.026912  0.044771  0.363208  0.582557\n",
       "27 -0.000737  0.000000  0.050992  0.044444  0.351533  0.582458\n",
       "28 -0.033945  0.003195  0.002833  0.038889  0.340383  0.579958\n",
       "29 -0.018466  0.012780  0.012748  0.037908  0.329513  0.578544\n",
       "30  0.010336  0.003195  0.050992  0.043246  0.319120  0.579123\n",
       "31 -0.004431  0.022364  0.012748  0.032135  0.308812  0.578670"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.squeeze(train_data[23]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "19/19 - 0s - loss: 1.5990 - accuracy: 0.3761 - 404ms/epoch - 21ms/step\n",
      "Epoch 2/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 103ms/epoch - 5ms/step\n",
      "Epoch 3/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 106ms/epoch - 6ms/step\n",
      "Epoch 4/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 124ms/epoch - 7ms/step\n",
      "Epoch 5/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 103ms/epoch - 5ms/step\n",
      "Epoch 6/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 105ms/epoch - 6ms/step\n",
      "Epoch 7/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 103ms/epoch - 5ms/step\n",
      "Epoch 8/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 94ms/epoch - 5ms/step\n",
      "Epoch 9/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 95ms/epoch - 5ms/step\n",
      "Epoch 10/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 95ms/epoch - 5ms/step\n",
      "Epoch 11/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 96ms/epoch - 5ms/step\n",
      "Epoch 12/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 96ms/epoch - 5ms/step\n",
      "Epoch 13/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 104ms/epoch - 5ms/step\n",
      "Epoch 14/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 97ms/epoch - 5ms/step\n",
      "Epoch 15/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 96ms/epoch - 5ms/step\n",
      "Epoch 16/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 98ms/epoch - 5ms/step\n",
      "Epoch 17/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 97ms/epoch - 5ms/step\n",
      "Epoch 18/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 99ms/epoch - 5ms/step\n",
      "Epoch 19/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 98ms/epoch - 5ms/step\n",
      "Epoch 20/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 99ms/epoch - 5ms/step\n",
      "Epoch 21/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 101ms/epoch - 5ms/step\n",
      "Epoch 22/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 98ms/epoch - 5ms/step\n",
      "Epoch 23/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 97ms/epoch - 5ms/step\n",
      "Epoch 24/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 95ms/epoch - 5ms/step\n",
      "Epoch 25/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 95ms/epoch - 5ms/step\n",
      "Epoch 26/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 101ms/epoch - 5ms/step\n",
      "Epoch 27/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 97ms/epoch - 5ms/step\n",
      "Epoch 28/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 98ms/epoch - 5ms/step\n",
      "Epoch 29/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 97ms/epoch - 5ms/step\n",
      "Epoch 30/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 96ms/epoch - 5ms/step\n",
      "Epoch 31/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 96ms/epoch - 5ms/step\n",
      "Epoch 32/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 96ms/epoch - 5ms/step\n",
      "Epoch 33/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 103ms/epoch - 5ms/step\n",
      "Epoch 34/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 94ms/epoch - 5ms/step\n",
      "Epoch 35/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 101ms/epoch - 5ms/step\n",
      "Epoch 36/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 118ms/epoch - 6ms/step\n",
      "Epoch 37/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 107ms/epoch - 6ms/step\n",
      "Epoch 38/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 96ms/epoch - 5ms/step\n",
      "Epoch 39/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 97ms/epoch - 5ms/step\n",
      "Epoch 40/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 101ms/epoch - 5ms/step\n",
      "Epoch 41/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 104ms/epoch - 5ms/step\n",
      "Epoch 42/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 95ms/epoch - 5ms/step\n",
      "Epoch 43/200\n",
      "19/19 - 0s - loss: 1.0986 - accuracy: 0.3778 - 95ms/epoch - 5ms/step\n",
      "Epoch 44/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/alint/Desktop/CTFlearn/digi/PyCourse/Cnn.ipynb Cell 28'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/alint/Desktop/CTFlearn/digi/PyCourse/Cnn.ipynb#ch0000023?line=0'>1</a>\u001b[0m model_2_history \u001b[39m=\u001b[39m model_2\u001b[39m.\u001b[39;49mfit( train_data, train_labels ,verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m , epochs \u001b[39m=\u001b[39;49m \u001b[39m200\u001b[39;49m,shuffle\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ee3717197db56dab91ad083a26bef10706ce761f0ab8e349ac843a6f8d1f4192"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
