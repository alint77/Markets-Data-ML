{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.utils as utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "import ta \n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "csvFileAddress = 'csv\\FTSE100_M15_202101210130_202206271215.csv'\n",
    "\n",
    "DJ = pd.read_csv(csvFileAddress,delim_whitespace=True)\n",
    "\n",
    "DJ['<ISGREEN>'] =  DJ['<CLOSE>'] > DJ['<OPEN>']\n",
    "DJ['<SIZE>'] =  (DJ['<CLOSE>'] - DJ['<OPEN>']) / DJ['<CLOSE>'] *100\n",
    "DJ['<VOLATILITY>'] =  DJ['<HIGH>'] - DJ['<LOW>'] /DJ['<CLOSE>']\n",
    "\n",
    "DJ.drop(['<VOL>'],axis=1,inplace=True)\n",
    "\n",
    "DJ.fillna(0,inplace=True)\n",
    "\n",
    "DJ['<EMA30>']= ta.trend.ema_indicator( DJ['<CLOSE>'],window=30)\n",
    "DJ['<EMA50>']= ta.trend.ema_indicator( DJ['<CLOSE>'],window=50)\n",
    "DJ['<EMA200>']= ta.trend.ema_indicator( DJ['<CLOSE>'],window=200)\n",
    "\n",
    "def Upper(e):\n",
    "    if e['<ISGREEN>'] : \n",
    "        return e['<HIGH>']-e['<CLOSE>']\n",
    "    return e['<HIGH>']-e['<OPEN>']\n",
    "\n",
    "def Lower(e):\n",
    "    if e['<ISGREEN>'] : \n",
    "        return e['<OPEN>']-e['<LOW>']\n",
    "    return e['<CLOSE>']-e['<LOW>']\n",
    "\n",
    "\n",
    "DJ['<UPPER>'] = DJ.apply(Upper,axis=1)\n",
    "DJ['<LOWER>'] = DJ.apply(Lower,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Adding TA indicators : \n",
    "\n",
    "from ta.volatility import BollingerBands,KeltnerChannel,average_true_range\n",
    "from ta.trend import MACD\n",
    "\n",
    "DJ['<RSI>'] = ta.momentum.rsi(DJ['<CLOSE>'],window=15,fillna=1) / 100\n",
    "# DJ['<CCI>'] = ta.trend.cci(close=DJ['<CLOSE>'],high=DJ['<HIGH>'],low=DJ['<LOW>'],window=14,fillna=1)\n",
    "\n",
    "\n",
    "keltner = KeltnerChannel(close=DJ['<CLOSE>'],high=DJ['<HIGH>'],low=DJ['<LOW>'],window=50,window_atr=20,multiplier=3,fillna=1)\n",
    "DJ['<KELTNER_H>'] = keltner.keltner_channel_hband()\n",
    "DJ['<KELTNER_L>'] = keltner.keltner_channel_lband()\n",
    "DJ['<KELTNER_M>'] = keltner.keltner_channel_mband()\n",
    "\n",
    "DJ['<KELT_L_IND>'] = keltner.keltner_channel_lband_indicator()\n",
    "DJ['<KELT_H_IND>'] = keltner.keltner_channel_hband_indicator()\n",
    "\n",
    "\n",
    "\n",
    "bollinger =BollingerBands(close=DJ['<CLOSE>'],window=50,window_dev=3,fillna=True)\n",
    "DJ['<BOL_H_IND>']=bollinger.bollinger_hband_indicator()\n",
    "DJ['<BOL_L_IND>']=bollinger.bollinger_lband_indicator()\n",
    "\n",
    "# macd = MACD(DJ['<CLOSE>'],fillna=True)\n",
    "\n",
    "\n",
    "DJ['<ATR_24>'] = average_true_range(close=DJ['<CLOSE>'],high=DJ['<HIGH>'],low=DJ['<LOW>'],window=30).apply(lambda e : e/100)\n",
    "DJ['<ATR_24_MULT>'] =abs(DJ['<SIZE>']) / DJ['<ATR_24>'] \n",
    "\n",
    "\n",
    "DJ[\"<ISGREEN>\"] = DJ[\"<ISGREEN>\"].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeFrame = (int(DJ.iloc[1][1][1])-int(DJ.iloc[0][1][1]) ) * 60 + (int(DJ.iloc[1][1][3:5])-int(DJ.iloc[0][1][3:5]))\n",
    "CandlesInDay = 24 * (60//timeFrame)\n",
    "timeFrame\n",
    "def candleToTime(j):\n",
    "    minuteMult = CandlesInDay//24\n",
    "    k=j//minuteMult\n",
    "    sth=timeFrame*(j%minuteMult)\n",
    "    return '{:02d}:{:02d}:00'.format(k,sth)\n",
    "\n",
    "uniqueDays = DJ.drop_duplicates(subset='<DATE>')\n",
    "uniqueDays = pd.DataFrame(uniqueDays)\n",
    "\n",
    "uniqueDaysCount=uniqueDays.shape[0]\n",
    "\n",
    "newnumparr = np.full((uniqueDaysCount*CandlesInDay,2),'',dtype=np.object_)\n",
    "\n",
    "\n",
    "for i in range(uniqueDaysCount):\n",
    "    for j in range(CandlesInDay):\n",
    "        newnumparr[(i*CandlesInDay)+j]=[uniqueDays.iloc[i][0],candleToTime(j)]\n",
    "\n",
    "newDF = pd.DataFrame(newnumparr,columns=['<DATE>','<TIME>'])\n",
    "\n",
    "newestDF = newDF.merge(DJ,on=['<DATE>','<TIME>'],how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "newestDF.drop(range(CandlesInDay),inplace=True)\n",
    "newestDF.fillna(0.0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;OPEN&gt;</th>\n",
       "      <th>&lt;HIGH&gt;</th>\n",
       "      <th>&lt;LOW&gt;</th>\n",
       "      <th>&lt;CLOSE&gt;</th>\n",
       "      <th>&lt;TICKVOL&gt;</th>\n",
       "      <th>&lt;SPREAD&gt;</th>\n",
       "      <th>&lt;ISGREEN&gt;</th>\n",
       "      <th>&lt;SIZE&gt;</th>\n",
       "      <th>&lt;VOLATILITY&gt;</th>\n",
       "      <th>&lt;EMA30&gt;</th>\n",
       "      <th>...</th>\n",
       "      <th>&lt;RSI&gt;</th>\n",
       "      <th>&lt;KELTNER_H&gt;</th>\n",
       "      <th>&lt;KELTNER_L&gt;</th>\n",
       "      <th>&lt;KELTNER_M&gt;</th>\n",
       "      <th>&lt;KELT_L_IND&gt;</th>\n",
       "      <th>&lt;KELT_H_IND&gt;</th>\n",
       "      <th>&lt;BOL_H_IND&gt;</th>\n",
       "      <th>&lt;BOL_L_IND&gt;</th>\n",
       "      <th>&lt;ATR_24&gt;</th>\n",
       "      <th>&lt;ATR_24_MULT&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>34464.000000</td>\n",
       "      <td>34464.000000</td>\n",
       "      <td>34464.000000</td>\n",
       "      <td>34464.000000</td>\n",
       "      <td>34464.000000</td>\n",
       "      <td>34464.000000</td>\n",
       "      <td>34464.000000</td>\n",
       "      <td>34464.000000</td>\n",
       "      <td>34464.000000</td>\n",
       "      <td>34464.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>34464.000000</td>\n",
       "      <td>34464.000000</td>\n",
       "      <td>34464.000000</td>\n",
       "      <td>34464.000000</td>\n",
       "      <td>34464.000000</td>\n",
       "      <td>34464.000000</td>\n",
       "      <td>34464.000000</td>\n",
       "      <td>34464.000000</td>\n",
       "      <td>34464.000000</td>\n",
       "      <td>34464.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6378.843759</td>\n",
       "      <td>6383.062451</td>\n",
       "      <td>6374.529065</td>\n",
       "      <td>6378.862787</td>\n",
       "      <td>414.946176</td>\n",
       "      <td>8.388986</td>\n",
       "      <td>0.443680</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>6382.171895</td>\n",
       "      <td>6378.638973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.452760</td>\n",
       "      <td>6386.971765</td>\n",
       "      <td>6369.910793</td>\n",
       "      <td>6378.441279</td>\n",
       "      <td>0.275592</td>\n",
       "      <td>0.343141</td>\n",
       "      <td>0.006906</td>\n",
       "      <td>0.009575</td>\n",
       "      <td>0.086448</td>\n",
       "      <td>0.629485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2245.848680</td>\n",
       "      <td>2247.318626</td>\n",
       "      <td>2244.345812</td>\n",
       "      <td>2245.855599</td>\n",
       "      <td>405.587873</td>\n",
       "      <td>21.762404</td>\n",
       "      <td>0.496825</td>\n",
       "      <td>0.096075</td>\n",
       "      <td>2247.009693</td>\n",
       "      <td>2245.717827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190603</td>\n",
       "      <td>2248.633274</td>\n",
       "      <td>2242.676935</td>\n",
       "      <td>2245.651743</td>\n",
       "      <td>0.446819</td>\n",
       "      <td>0.474765</td>\n",
       "      <td>0.082815</td>\n",
       "      <td>0.097385</td>\n",
       "      <td>0.048570</td>\n",
       "      <td>0.672775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.020394</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6890.600000</td>\n",
       "      <td>6894.675000</td>\n",
       "      <td>6886.400000</td>\n",
       "      <td>6890.875000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.037516</td>\n",
       "      <td>6893.676930</td>\n",
       "      <td>6892.021895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393835</td>\n",
       "      <td>6899.108667</td>\n",
       "      <td>6883.483167</td>\n",
       "      <td>6891.719167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062664</td>\n",
       "      <td>0.145783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7111.600000</td>\n",
       "      <td>7115.550000</td>\n",
       "      <td>7106.800000</td>\n",
       "      <td>7111.500000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7114.550626</td>\n",
       "      <td>7111.243270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.494420</td>\n",
       "      <td>7118.753667</td>\n",
       "      <td>7101.471000</td>\n",
       "      <td>7110.366333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082196</td>\n",
       "      <td>0.446326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7340.600000</td>\n",
       "      <td>7345.300000</td>\n",
       "      <td>7335.125000</td>\n",
       "      <td>7340.600000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.039900</td>\n",
       "      <td>7344.300136</td>\n",
       "      <td>7343.345985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.576572</td>\n",
       "      <td>7351.176167</td>\n",
       "      <td>7334.188000</td>\n",
       "      <td>7343.813000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109155</td>\n",
       "      <td>0.894164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7692.700000</td>\n",
       "      <td>7694.700000</td>\n",
       "      <td>7684.200000</td>\n",
       "      <td>7692.700000</td>\n",
       "      <td>3724.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.382513</td>\n",
       "      <td>7693.701300</td>\n",
       "      <td>7672.180191</td>\n",
       "      <td>...</td>\n",
       "      <td>0.912642</td>\n",
       "      <td>7676.910667</td>\n",
       "      <td>7654.264000</td>\n",
       "      <td>7665.502667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.340014</td>\n",
       "      <td>8.800167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             <OPEN>        <HIGH>         <LOW>       <CLOSE>     <TICKVOL>  \\\n",
       "count  34464.000000  34464.000000  34464.000000  34464.000000  34464.000000   \n",
       "mean    6378.843759   6383.062451   6374.529065   6378.862787    414.946176   \n",
       "std     2245.848680   2247.318626   2244.345812   2245.855599    405.587873   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%     6890.600000   6894.675000   6886.400000   6890.875000    135.000000   \n",
       "50%     7111.600000   7115.550000   7106.800000   7111.500000    297.000000   \n",
       "75%     7340.600000   7345.300000   7335.125000   7340.600000    570.000000   \n",
       "max     7692.700000   7694.700000   7684.200000   7692.700000   3724.000000   \n",
       "\n",
       "           <SPREAD>     <ISGREEN>        <SIZE>  <VOLATILITY>       <EMA30>  \\\n",
       "count  34464.000000  34464.000000  34464.000000  34464.000000  34464.000000   \n",
       "mean       8.388986      0.443680      0.000219   6382.171895   6378.638973   \n",
       "std       21.762404      0.496825      0.096075   2247.009693   2245.717827   \n",
       "min        0.000000      0.000000     -1.020394      0.000000      0.000000   \n",
       "25%        1.000000      0.000000     -0.037516   6893.676930   6892.021895   \n",
       "50%        2.000000      0.000000      0.000000   7114.550626   7111.243270   \n",
       "75%        4.000000      1.000000      0.039900   7344.300136   7343.345985   \n",
       "max      105.000000      1.000000      1.382513   7693.701300   7672.180191   \n",
       "\n",
       "       ...         <RSI>   <KELTNER_H>   <KELTNER_L>   <KELTNER_M>  \\\n",
       "count  ...  34464.000000  34464.000000  34464.000000  34464.000000   \n",
       "mean   ...      0.452760   6386.971765   6369.910793   6378.441279   \n",
       "std    ...      0.190603   2248.633274   2242.676935   2245.651743   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.393835   6899.108667   6883.483167   6891.719167   \n",
       "50%    ...      0.494420   7118.753667   7101.471000   7110.366333   \n",
       "75%    ...      0.576572   7351.176167   7334.188000   7343.813000   \n",
       "max    ...      0.912642   7676.910667   7654.264000   7665.502667   \n",
       "\n",
       "       <KELT_L_IND>  <KELT_H_IND>   <BOL_H_IND>   <BOL_L_IND>      <ATR_24>  \\\n",
       "count  34464.000000  34464.000000  34464.000000  34464.000000  34464.000000   \n",
       "mean       0.275592      0.343141      0.006906      0.009575      0.086448   \n",
       "std        0.446819      0.474765      0.082815      0.097385      0.048570   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.062664   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.082196   \n",
       "75%        1.000000      1.000000      0.000000      0.000000      0.109155   \n",
       "max        1.000000      1.000000      1.000000      1.000000      0.340014   \n",
       "\n",
       "       <ATR_24_MULT>  \n",
       "count   34464.000000  \n",
       "mean        0.629485  \n",
       "std         0.672775  \n",
       "min         0.000000  \n",
       "25%         0.145783  \n",
       "50%         0.446326  \n",
       "75%         0.894164  \n",
       "max         8.800167  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newestDF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import multiprocessing\n",
    "import mp\n",
    "\n",
    "\n",
    "\n",
    "df = newestDF.drop(['<DATE>','<TIME>'],axis=1)\n",
    "threadCount = 12\n",
    "\n",
    "trainNps=[]\n",
    "labelValues = []\n",
    "\n",
    "for i in range(threadCount): trainNps.append([])\n",
    "for i in range(threadCount): labelValues.append([])\n",
    "\n",
    "maxValues = df.max()\n",
    "\n",
    "lenDFthread =  len(df) / threadCount\n",
    "threads = []\n",
    "p = multiprocessing.Pool(threadCount)\n",
    "out=p.starmap(mp.thread_function,[(df.iloc[int(index*lenDFthread):int((1+index)*lenDFthread-1)],index,CandlesInDay) for index in range(threadCount)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 2, 1363)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(out,dtype=np.object_).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas=[]\n",
    "labs=[]\n",
    "for i in range(threadCount): \n",
    "    datas = datas+out[i][0]\n",
    "    labs = labs + out[i][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16356, 16356)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datas),len(labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12267, 12267)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "l = len(datas)\n",
    "windows2= np.array(datas)\n",
    "\n",
    "labs = np.array(labs)\n",
    "\n",
    "\n",
    "train_data = windows2[:int(l*.75)]\n",
    "val_data = windows2[int(l*.75)+1:]\n",
    "\n",
    "\n",
    "\n",
    "train_labels = labs[:int(l*.75)].astype(np.uint8)\n",
    "val_labels = labs[int(l*.75)+1:].astype(np.uint8)\n",
    "\n",
    "\n",
    "len(train_data),len(train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4088, 4088)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_data),len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "signal\n",
       "0         0.406823\n",
       "2         0.309122\n",
       "1         0.284055\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(labs,columns=['signal']).value_counts()/len(labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 12, 32)            4992      \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 12, 64)            24832     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 128)               98816     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               12900     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 303       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 141,843\n",
      "Trainable params: 141,843\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D,LSTM, ConvLSTM1D,Flatten,SimpleRNN,GRU,AveragePooling2D\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model_rnn = keras.Sequential([\n",
    "    LSTM(32,input_shape=train_data[0].shape,dropout=.1,return_sequences=1),\n",
    "    LSTM(64,dropout=.1,return_sequences=1),\n",
    "    LSTM(128,dropout=.1,return_sequences=0),\n",
    "    # Flatten(),\n",
    "    Dense(100,activation='relu'),\n",
    "    Dense(3,activation='sigmoid'),\n",
    "\n",
    "])\n",
    "\n",
    "model_rnn.compile(\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer = 'adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 - 6s - loss: 1.0949 - accuracy: 0.3333 - val_loss: 1.0861 - val_accuracy: 0.5000 - 6s/epoch - 6s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 1.0740 - accuracy: 0.5556 - val_loss: 1.0759 - val_accuracy: 0.5000 - 38ms/epoch - 38ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 1.0586 - accuracy: 0.5556 - val_loss: 1.0666 - val_accuracy: 0.5000 - 37ms/epoch - 37ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 1.0392 - accuracy: 0.5556 - val_loss: 1.0597 - val_accuracy: 0.5000 - 37ms/epoch - 37ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 1.0172 - accuracy: 0.5556 - val_loss: 1.0543 - val_accuracy: 0.5000 - 37ms/epoch - 37ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 0.9902 - accuracy: 0.5556 - val_loss: 1.0498 - val_accuracy: 0.5000 - 37ms/epoch - 37ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 0.9593 - accuracy: 0.5556 - val_loss: 1.0476 - val_accuracy: 0.5000 - 38ms/epoch - 38ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 0.9302 - accuracy: 0.5556 - val_loss: 1.0502 - val_accuracy: 0.5000 - 37ms/epoch - 37ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 0.8836 - accuracy: 0.5556 - val_loss: 1.0643 - val_accuracy: 0.5000 - 36ms/epoch - 36ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 0.8470 - accuracy: 0.5556 - val_loss: 1.0988 - val_accuracy: 0.5000 - 36ms/epoch - 36ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 0.8403 - accuracy: 0.5556 - val_loss: 1.1417 - val_accuracy: 0.5000 - 35ms/epoch - 35ms/step\n",
      "Epoch 12/200\n",
      "1/1 - 0s - loss: 0.8328 - accuracy: 0.5556 - val_loss: 1.1565 - val_accuracy: 0.5000 - 39ms/epoch - 39ms/step\n",
      "Epoch 13/200\n",
      "1/1 - 0s - loss: 0.8299 - accuracy: 0.5556 - val_loss: 1.1382 - val_accuracy: 0.5000 - 37ms/epoch - 37ms/step\n",
      "Epoch 14/200\n",
      "1/1 - 0s - loss: 0.8195 - accuracy: 0.5556 - val_loss: 1.0984 - val_accuracy: 0.5000 - 35ms/epoch - 35ms/step\n",
      "Epoch 15/200\n",
      "1/1 - 0s - loss: 0.7998 - accuracy: 0.5556 - val_loss: 1.0536 - val_accuracy: 0.5000 - 36ms/epoch - 36ms/step\n",
      "Epoch 16/200\n",
      "1/1 - 0s - loss: 0.7800 - accuracy: 0.5556 - val_loss: 1.0150 - val_accuracy: 0.5000 - 35ms/epoch - 35ms/step\n",
      "Epoch 17/200\n",
      "1/1 - 0s - loss: 0.7646 - accuracy: 0.6667 - val_loss: 0.9921 - val_accuracy: 0.0000e+00 - 37ms/epoch - 37ms/step\n",
      "Epoch 18/200\n",
      "1/1 - 0s - loss: 0.7488 - accuracy: 0.6667 - val_loss: 0.9839 - val_accuracy: 0.0000e+00 - 38ms/epoch - 38ms/step\n",
      "Epoch 19/200\n",
      "1/1 - 0s - loss: 0.7457 - accuracy: 0.5556 - val_loss: 0.9858 - val_accuracy: 0.0000e+00 - 39ms/epoch - 39ms/step\n",
      "Epoch 20/200\n",
      "1/1 - 0s - loss: 0.7342 - accuracy: 0.5556 - val_loss: 0.9868 - val_accuracy: 0.0000e+00 - 37ms/epoch - 37ms/step\n",
      "Epoch 21/200\n",
      "1/1 - 0s - loss: 0.7394 - accuracy: 0.5556 - val_loss: 0.9803 - val_accuracy: 0.0000e+00 - 37ms/epoch - 37ms/step\n",
      "Epoch 22/200\n",
      "1/1 - 0s - loss: 0.6990 - accuracy: 0.7778 - val_loss: 0.9836 - val_accuracy: 0.5000 - 38ms/epoch - 38ms/step\n",
      "Epoch 23/200\n",
      "1/1 - 0s - loss: 0.7003 - accuracy: 0.6667 - val_loss: 0.9968 - val_accuracy: 0.5000 - 35ms/epoch - 35ms/step\n",
      "Epoch 24/200\n",
      "1/1 - 0s - loss: 0.6822 - accuracy: 0.6667 - val_loss: 1.0228 - val_accuracy: 0.5000 - 34ms/epoch - 34ms/step\n",
      "Epoch 25/200\n",
      "1/1 - 0s - loss: 0.6489 - accuracy: 0.5556 - val_loss: 1.0722 - val_accuracy: 0.5000 - 35ms/epoch - 35ms/step\n",
      "Epoch 26/200\n",
      "1/1 - 0s - loss: 0.6532 - accuracy: 0.6667 - val_loss: 1.1236 - val_accuracy: 0.5000 - 37ms/epoch - 37ms/step\n",
      "Epoch 27/200\n",
      "1/1 - 0s - loss: 0.6469 - accuracy: 0.6667 - val_loss: 1.1559 - val_accuracy: 0.5000 - 36ms/epoch - 36ms/step\n",
      "Epoch 28/200\n",
      "1/1 - 0s - loss: 0.5961 - accuracy: 0.8889 - val_loss: 1.2057 - val_accuracy: 0.5000 - 37ms/epoch - 37ms/step\n",
      "Epoch 29/200\n",
      "1/1 - 0s - loss: 0.5668 - accuracy: 0.8889 - val_loss: 1.2520 - val_accuracy: 0.5000 - 35ms/epoch - 35ms/step\n",
      "Epoch 30/200\n",
      "1/1 - 0s - loss: 0.5488 - accuracy: 0.8889 - val_loss: 1.2303 - val_accuracy: 0.5000 - 36ms/epoch - 36ms/step\n",
      "Epoch 31/200\n",
      "1/1 - 0s - loss: 0.5218 - accuracy: 0.8889 - val_loss: 1.2450 - val_accuracy: 0.5000 - 35ms/epoch - 35ms/step\n",
      "Epoch 32/200\n",
      "1/1 - 0s - loss: 0.4781 - accuracy: 0.8889 - val_loss: 1.3500 - val_accuracy: 0.0000e+00 - 37ms/epoch - 37ms/step\n",
      "Epoch 33/200\n",
      "1/1 - 0s - loss: 0.4408 - accuracy: 0.8889 - val_loss: 1.2896 - val_accuracy: 0.0000e+00 - 35ms/epoch - 35ms/step\n",
      "Epoch 34/200\n",
      "1/1 - 0s - loss: 0.4029 - accuracy: 0.8889 - val_loss: 1.3005 - val_accuracy: 0.0000e+00 - 37ms/epoch - 37ms/step\n",
      "Epoch 35/200\n",
      "1/1 - 0s - loss: 0.3697 - accuracy: 0.8889 - val_loss: 1.1851 - val_accuracy: 0.5000 - 37ms/epoch - 37ms/step\n",
      "Epoch 36/200\n",
      "1/1 - 0s - loss: 0.3422 - accuracy: 0.8889 - val_loss: 1.1771 - val_accuracy: 0.5000 - 36ms/epoch - 36ms/step\n",
      "Epoch 37/200\n",
      "1/1 - 0s - loss: 0.3447 - accuracy: 0.8889 - val_loss: 1.4474 - val_accuracy: 0.0000e+00 - 36ms/epoch - 36ms/step\n",
      "Epoch 38/200\n",
      "1/1 - 0s - loss: 0.3426 - accuracy: 0.8889 - val_loss: 1.0772 - val_accuracy: 0.5000 - 36ms/epoch - 36ms/step\n",
      "Epoch 39/200\n",
      "1/1 - 0s - loss: 0.3015 - accuracy: 0.8889 - val_loss: 0.9053 - val_accuracy: 0.5000 - 38ms/epoch - 38ms/step\n",
      "Epoch 40/200\n",
      "1/1 - 0s - loss: 0.2908 - accuracy: 0.8889 - val_loss: 0.9110 - val_accuracy: 0.5000 - 36ms/epoch - 36ms/step\n",
      "Epoch 41/200\n",
      "1/1 - 0s - loss: 0.2769 - accuracy: 0.8889 - val_loss: 0.9543 - val_accuracy: 0.5000 - 36ms/epoch - 36ms/step\n",
      "Epoch 42/200\n",
      "1/1 - 0s - loss: 0.2731 - accuracy: 0.8889 - val_loss: 1.0616 - val_accuracy: 0.5000 - 35ms/epoch - 35ms/step\n",
      "Epoch 43/200\n",
      "1/1 - 0s - loss: 0.2714 - accuracy: 0.8889 - val_loss: 1.1092 - val_accuracy: 0.5000 - 36ms/epoch - 36ms/step\n",
      "Epoch 44/200\n",
      "1/1 - 0s - loss: 0.2253 - accuracy: 0.8889 - val_loss: 1.1852 - val_accuracy: 0.5000 - 37ms/epoch - 37ms/step\n",
      "Epoch 45/200\n",
      "1/1 - 0s - loss: 0.2340 - accuracy: 0.8889 - val_loss: 1.3325 - val_accuracy: 0.5000 - 36ms/epoch - 36ms/step\n",
      "Epoch 46/200\n",
      "1/1 - 0s - loss: 0.2248 - accuracy: 0.8889 - val_loss: 1.5862 - val_accuracy: 0.5000 - 35ms/epoch - 35ms/step\n",
      "Epoch 47/200\n",
      "1/1 - 0s - loss: 0.2233 - accuracy: 0.8889 - val_loss: 1.9561 - val_accuracy: 0.0000e+00 - 42ms/epoch - 42ms/step\n",
      "Epoch 48/200\n",
      "1/1 - 0s - loss: 0.2645 - accuracy: 0.8889 - val_loss: 2.8250 - val_accuracy: 0.0000e+00 - 44ms/epoch - 44ms/step\n",
      "Epoch 49/200\n",
      "1/1 - 0s - loss: 0.2085 - accuracy: 0.8889 - val_loss: 3.4719 - val_accuracy: 0.0000e+00 - 39ms/epoch - 39ms/step\n",
      "Epoch 50/200\n",
      "1/1 - 0s - loss: 0.2132 - accuracy: 0.8889 - val_loss: 3.9732 - val_accuracy: 0.0000e+00 - 37ms/epoch - 37ms/step\n",
      "Epoch 51/200\n",
      "1/1 - 0s - loss: 0.1966 - accuracy: 0.8889 - val_loss: 4.2223 - val_accuracy: 0.0000e+00 - 37ms/epoch - 37ms/step\n",
      "Epoch 52/200\n",
      "1/1 - 0s - loss: 0.2393 - accuracy: 0.8889 - val_loss: 4.6124 - val_accuracy: 0.0000e+00 - 38ms/epoch - 38ms/step\n",
      "Epoch 53/200\n",
      "1/1 - 0s - loss: 0.1897 - accuracy: 0.8889 - val_loss: 5.0803 - val_accuracy: 0.0000e+00 - 36ms/epoch - 36ms/step\n",
      "Epoch 54/200\n",
      "1/1 - 0s - loss: 0.2106 - accuracy: 0.8889 - val_loss: 5.1936 - val_accuracy: 0.0000e+00 - 37ms/epoch - 37ms/step\n",
      "Epoch 55/200\n",
      "1/1 - 0s - loss: 0.1762 - accuracy: 0.8889 - val_loss: 5.3909 - val_accuracy: 0.0000e+00 - 34ms/epoch - 34ms/step\n",
      "Epoch 56/200\n",
      "1/1 - 0s - loss: 0.1729 - accuracy: 0.8889 - val_loss: 5.5550 - val_accuracy: 0.0000e+00 - 36ms/epoch - 36ms/step\n",
      "Epoch 57/200\n",
      "1/1 - 0s - loss: 0.1420 - accuracy: 1.0000 - val_loss: 5.6608 - val_accuracy: 0.0000e+00 - 36ms/epoch - 36ms/step\n",
      "Epoch 58/200\n",
      "1/1 - 0s - loss: 0.1951 - accuracy: 0.8889 - val_loss: 5.7114 - val_accuracy: 0.0000e+00 - 35ms/epoch - 35ms/step\n",
      "Epoch 59/200\n",
      "1/1 - 0s - loss: 0.1748 - accuracy: 0.8889 - val_loss: 5.7575 - val_accuracy: 0.0000e+00 - 37ms/epoch - 37ms/step\n",
      "Epoch 60/200\n",
      "1/1 - 0s - loss: 0.1778 - accuracy: 0.8889 - val_loss: 5.8177 - val_accuracy: 0.0000e+00 - 36ms/epoch - 36ms/step\n",
      "Epoch 61/200\n",
      "1/1 - 0s - loss: 0.2190 - accuracy: 0.7778 - val_loss: 5.7279 - val_accuracy: 0.0000e+00 - 39ms/epoch - 39ms/step\n",
      "Epoch 62/200\n",
      "1/1 - 0s - loss: 0.1567 - accuracy: 0.8889 - val_loss: 5.5755 - val_accuracy: 0.0000e+00 - 42ms/epoch - 42ms/step\n",
      "Epoch 63/200\n",
      "1/1 - 0s - loss: 0.1506 - accuracy: 0.8889 - val_loss: 5.3712 - val_accuracy: 0.0000e+00 - 37ms/epoch - 37ms/step\n",
      "Epoch 64/200\n",
      "1/1 - 0s - loss: 0.1956 - accuracy: 0.7778 - val_loss: 4.9505 - val_accuracy: 0.0000e+00 - 37ms/epoch - 37ms/step\n",
      "Epoch 65/200\n",
      "1/1 - 0s - loss: 0.2060 - accuracy: 1.0000 - val_loss: 4.6749 - val_accuracy: 0.0000e+00 - 40ms/epoch - 40ms/step\n",
      "Epoch 66/200\n",
      "1/1 - 0s - loss: 0.1646 - accuracy: 0.8889 - val_loss: 4.4790 - val_accuracy: 0.5000 - 39ms/epoch - 39ms/step\n",
      "Epoch 67/200\n",
      "1/1 - 0s - loss: 0.1615 - accuracy: 0.8889 - val_loss: 4.3897 - val_accuracy: 0.5000 - 39ms/epoch - 39ms/step\n",
      "Epoch 68/200\n",
      "1/1 - 0s - loss: 0.2135 - accuracy: 0.8889 - val_loss: 4.2733 - val_accuracy: 0.5000 - 39ms/epoch - 39ms/step\n",
      "Epoch 69/200\n",
      "1/1 - 0s - loss: 0.1931 - accuracy: 0.8889 - val_loss: 4.0974 - val_accuracy: 0.5000 - 40ms/epoch - 40ms/step\n",
      "Epoch 70/200\n",
      "1/1 - 0s - loss: 0.1503 - accuracy: 0.8889 - val_loss: 3.9334 - val_accuracy: 0.5000 - 38ms/epoch - 38ms/step\n",
      "Epoch 71/200\n",
      "1/1 - 0s - loss: 0.2044 - accuracy: 0.8889 - val_loss: 4.1182 - val_accuracy: 0.5000 - 36ms/epoch - 36ms/step\n",
      "Epoch 72/200\n",
      "1/1 - 0s - loss: 0.1519 - accuracy: 0.8889 - val_loss: 4.3051 - val_accuracy: 0.5000 - 38ms/epoch - 38ms/step\n",
      "Epoch 73/200\n",
      "1/1 - 0s - loss: 0.1613 - accuracy: 0.8889 - val_loss: 4.3343 - val_accuracy: 0.5000 - 41ms/epoch - 41ms/step\n",
      "Epoch 74/200\n",
      "1/1 - 0s - loss: 0.1492 - accuracy: 0.8889 - val_loss: 4.1687 - val_accuracy: 0.5000 - 39ms/epoch - 39ms/step\n",
      "Epoch 75/200\n",
      "1/1 - 0s - loss: 0.1640 - accuracy: 0.8889 - val_loss: 4.1375 - val_accuracy: 0.5000 - 37ms/epoch - 37ms/step\n",
      "Epoch 76/200\n",
      "1/1 - 0s - loss: 0.1189 - accuracy: 1.0000 - val_loss: 4.2905 - val_accuracy: 0.0000e+00 - 38ms/epoch - 38ms/step\n",
      "Epoch 77/200\n",
      "1/1 - 0s - loss: 0.1506 - accuracy: 0.8889 - val_loss: 4.5921 - val_accuracy: 0.0000e+00 - 38ms/epoch - 38ms/step\n",
      "Epoch 78/200\n",
      "1/1 - 0s - loss: 0.2554 - accuracy: 0.8889 - val_loss: 5.0531 - val_accuracy: 0.0000e+00 - 41ms/epoch - 41ms/step\n",
      "Epoch 79/200\n",
      "1/1 - 0s - loss: 0.2698 - accuracy: 0.7778 - val_loss: 5.8402 - val_accuracy: 0.0000e+00 - 39ms/epoch - 39ms/step\n",
      "Epoch 80/200\n",
      "1/1 - 0s - loss: 0.2679 - accuracy: 0.8889 - val_loss: 6.4673 - val_accuracy: 0.0000e+00 - 39ms/epoch - 39ms/step\n",
      "Epoch 81/200\n",
      "1/1 - 0s - loss: 0.1243 - accuracy: 0.8889 - val_loss: 6.9971 - val_accuracy: 0.0000e+00 - 36ms/epoch - 36ms/step\n",
      "Epoch 82/200\n",
      "1/1 - 0s - loss: 0.1408 - accuracy: 0.8889 - val_loss: 7.4139 - val_accuracy: 0.0000e+00 - 40ms/epoch - 40ms/step\n",
      "Epoch 83/200\n",
      "1/1 - 0s - loss: 0.6804 - accuracy: 0.7778 - val_loss: 7.9154 - val_accuracy: 0.0000e+00 - 38ms/epoch - 38ms/step\n",
      "Epoch 84/200\n",
      "1/1 - 0s - loss: 0.1821 - accuracy: 0.8889 - val_loss: 8.0314 - val_accuracy: 0.0000e+00 - 37ms/epoch - 37ms/step\n",
      "Epoch 85/200\n",
      "1/1 - 0s - loss: 0.1538 - accuracy: 0.8889 - val_loss: 7.9880 - val_accuracy: 0.0000e+00 - 37ms/epoch - 37ms/step\n",
      "Epoch 86/200\n",
      "1/1 - 0s - loss: 0.1581 - accuracy: 0.8889 - val_loss: 7.8747 - val_accuracy: 0.0000e+00 - 38ms/epoch - 38ms/step\n",
      "Epoch 87/200\n",
      "1/1 - 0s - loss: 0.1328 - accuracy: 0.8889 - val_loss: 7.7433 - val_accuracy: 0.0000e+00 - 36ms/epoch - 36ms/step\n",
      "Epoch 88/200\n",
      "1/1 - 0s - loss: 0.1831 - accuracy: 0.8889 - val_loss: 7.6489 - val_accuracy: 0.0000e+00 - 40ms/epoch - 40ms/step\n",
      "Epoch 89/200\n",
      "1/1 - 0s - loss: 0.2145 - accuracy: 0.8889 - val_loss: 7.6501 - val_accuracy: 0.0000e+00 - 38ms/epoch - 38ms/step\n",
      "Epoch 90/200\n",
      "1/1 - 0s - loss: 0.2091 - accuracy: 0.7778 - val_loss: 7.6803 - val_accuracy: 0.0000e+00 - 38ms/epoch - 38ms/step\n",
      "Epoch 91/200\n",
      "1/1 - 0s - loss: 0.1666 - accuracy: 0.8889 - val_loss: 7.7492 - val_accuracy: 0.0000e+00 - 37ms/epoch - 37ms/step\n",
      "Epoch 92/200\n",
      "1/1 - 0s - loss: 0.2162 - accuracy: 0.8889 - val_loss: 7.8258 - val_accuracy: 0.0000e+00 - 38ms/epoch - 38ms/step\n",
      "Epoch 93/200\n",
      "1/1 - 0s - loss: 0.7681 - accuracy: 0.7778 - val_loss: 3.5804 - val_accuracy: 0.5000 - 35ms/epoch - 35ms/step\n",
      "Epoch 94/200\n",
      "1/1 - 0s - loss: 0.1755 - accuracy: 0.8889 - val_loss: 3.6198 - val_accuracy: 0.5000 - 38ms/epoch - 38ms/step\n",
      "Epoch 95/200\n",
      "1/1 - 0s - loss: 0.1249 - accuracy: 0.8889 - val_loss: 3.6304 - val_accuracy: 0.5000 - 37ms/epoch - 37ms/step\n",
      "Epoch 96/200\n",
      "1/1 - 0s - loss: 1.1631 - accuracy: 0.7778 - val_loss: 3.4527 - val_accuracy: 0.5000 - 39ms/epoch - 39ms/step\n",
      "Epoch 97/200\n",
      "1/1 - 0s - loss: 1.8803 - accuracy: 0.7778 - val_loss: 3.0708 - val_accuracy: 0.5000 - 37ms/epoch - 37ms/step\n",
      "Epoch 98/200\n",
      "1/1 - 0s - loss: 1.2138 - accuracy: 0.6667 - val_loss: 2.6059 - val_accuracy: 0.5000 - 37ms/epoch - 37ms/step\n",
      "Epoch 99/200\n",
      "1/1 - 0s - loss: 0.8205 - accuracy: 0.8889 - val_loss: 2.1151 - val_accuracy: 0.5000 - 37ms/epoch - 37ms/step\n",
      "Epoch 100/200\n",
      "1/1 - 0s - loss: 0.1162 - accuracy: 1.0000 - val_loss: 1.7137 - val_accuracy: 0.5000 - 38ms/epoch - 38ms/step\n",
      "Epoch 101/200\n",
      "1/1 - 0s - loss: 0.1437 - accuracy: 1.0000 - val_loss: 3.3329 - val_accuracy: 0.0000e+00 - 44ms/epoch - 44ms/step\n",
      "Epoch 102/200\n",
      "1/1 - 0s - loss: 0.1584 - accuracy: 1.0000 - val_loss: 4.2117 - val_accuracy: 0.0000e+00 - 37ms/epoch - 37ms/step\n",
      "Epoch 103/200\n",
      "1/1 - 0s - loss: 0.2428 - accuracy: 0.8889 - val_loss: 4.6312 - val_accuracy: 0.0000e+00 - 38ms/epoch - 38ms/step\n",
      "Epoch 104/200\n",
      "1/1 - 0s - loss: 0.2180 - accuracy: 1.0000 - val_loss: 4.8066 - val_accuracy: 0.0000e+00 - 40ms/epoch - 40ms/step\n",
      "Epoch 105/200\n",
      "1/1 - 0s - loss: 0.7871 - accuracy: 0.8889 - val_loss: 4.7096 - val_accuracy: 0.0000e+00 - 38ms/epoch - 38ms/step\n",
      "Epoch 106/200\n",
      "1/1 - 0s - loss: 0.7043 - accuracy: 0.8889 - val_loss: 4.5458 - val_accuracy: 0.0000e+00 - 38ms/epoch - 38ms/step\n",
      "Epoch 107/200\n",
      "1/1 - 0s - loss: 0.4823 - accuracy: 0.8889 - val_loss: 4.3418 - val_accuracy: 0.0000e+00 - 38ms/epoch - 38ms/step\n",
      "Epoch 108/200\n",
      "1/1 - 0s - loss: 0.2646 - accuracy: 0.7778 - val_loss: 4.1059 - val_accuracy: 0.0000e+00 - 40ms/epoch - 40ms/step\n",
      "Epoch 109/200\n",
      "1/1 - 0s - loss: 0.4464 - accuracy: 0.8889 - val_loss: 3.6224 - val_accuracy: 0.0000e+00 - 39ms/epoch - 39ms/step\n",
      "Epoch 110/200\n",
      "1/1 - 0s - loss: 0.1967 - accuracy: 0.8889 - val_loss: 2.9154 - val_accuracy: 0.0000e+00 - 43ms/epoch - 43ms/step\n",
      "Epoch 111/200\n",
      "1/1 - 0s - loss: 0.1538 - accuracy: 0.8889 - val_loss: 2.4230 - val_accuracy: 0.0000e+00 - 37ms/epoch - 37ms/step\n",
      "Epoch 112/200\n",
      "1/1 - 0s - loss: 0.1798 - accuracy: 0.8889 - val_loss: 2.2062 - val_accuracy: 0.5000 - 40ms/epoch - 40ms/step\n",
      "Epoch 113/200\n",
      "1/1 - 0s - loss: 0.1069 - accuracy: 1.0000 - val_loss: 2.1550 - val_accuracy: 0.5000 - 38ms/epoch - 38ms/step\n",
      "Epoch 114/200\n",
      "1/1 - 0s - loss: 0.1061 - accuracy: 1.0000 - val_loss: 2.1748 - val_accuracy: 0.5000 - 38ms/epoch - 38ms/step\n",
      "Epoch 115/200\n",
      "1/1 - 0s - loss: 0.1200 - accuracy: 1.0000 - val_loss: 2.2149 - val_accuracy: 0.5000 - 38ms/epoch - 38ms/step\n",
      "Epoch 116/200\n",
      "1/1 - 0s - loss: 0.1288 - accuracy: 1.0000 - val_loss: 2.2691 - val_accuracy: 0.5000 - 40ms/epoch - 40ms/step\n",
      "Epoch 117/200\n",
      "1/1 - 0s - loss: 0.1069 - accuracy: 1.0000 - val_loss: 2.3186 - val_accuracy: 0.5000 - 37ms/epoch - 37ms/step\n",
      "Epoch 118/200\n",
      "1/1 - 0s - loss: 0.2479 - accuracy: 0.8889 - val_loss: 2.3581 - val_accuracy: 0.5000 - 39ms/epoch - 39ms/step\n",
      "Epoch 119/200\n",
      "1/1 - 0s - loss: 0.1516 - accuracy: 0.8889 - val_loss: 2.3666 - val_accuracy: 0.5000 - 36ms/epoch - 36ms/step\n",
      "Epoch 120/200\n",
      "1/1 - 0s - loss: 0.0934 - accuracy: 1.0000 - val_loss: 2.3710 - val_accuracy: 0.5000 - 39ms/epoch - 39ms/step\n",
      "Epoch 121/200\n",
      "1/1 - 0s - loss: 0.0994 - accuracy: 1.0000 - val_loss: 2.3695 - val_accuracy: 0.5000 - 35ms/epoch - 35ms/step\n",
      "Epoch 122/200\n",
      "1/1 - 0s - loss: 0.2619 - accuracy: 0.8889 - val_loss: 2.3648 - val_accuracy: 0.5000 - 40ms/epoch - 40ms/step\n",
      "Epoch 123/200\n",
      "1/1 - 0s - loss: 0.1718 - accuracy: 0.8889 - val_loss: 2.3574 - val_accuracy: 0.5000 - 37ms/epoch - 37ms/step\n",
      "Epoch 124/200\n",
      "1/1 - 0s - loss: 0.1764 - accuracy: 0.8889 - val_loss: 2.3474 - val_accuracy: 0.5000 - 40ms/epoch - 40ms/step\n",
      "Epoch 125/200\n",
      "1/1 - 0s - loss: 0.2173 - accuracy: 0.8889 - val_loss: 2.3863 - val_accuracy: 0.5000 - 38ms/epoch - 38ms/step\n",
      "Epoch 126/200\n",
      "1/1 - 0s - loss: 0.1501 - accuracy: 1.0000 - val_loss: 2.4421 - val_accuracy: 0.5000 - 41ms/epoch - 41ms/step\n",
      "Epoch 127/200\n",
      "1/1 - 0s - loss: 0.1235 - accuracy: 0.8889 - val_loss: 2.5199 - val_accuracy: 0.5000 - 40ms/epoch - 40ms/step\n",
      "Epoch 128/200\n",
      "1/1 - 0s - loss: 0.0809 - accuracy: 1.0000 - val_loss: 2.6309 - val_accuracy: 0.5000 - 41ms/epoch - 41ms/step\n",
      "Epoch 129/200\n",
      "1/1 - 0s - loss: 0.1948 - accuracy: 0.8889 - val_loss: 2.8059 - val_accuracy: 0.5000 - 42ms/epoch - 42ms/step\n",
      "Epoch 130/200\n",
      "1/1 - 0s - loss: 0.1729 - accuracy: 0.8889 - val_loss: 3.0524 - val_accuracy: 0.0000e+00 - 42ms/epoch - 42ms/step\n",
      "Epoch 131/200\n",
      "1/1 - 0s - loss: 0.1368 - accuracy: 0.8889 - val_loss: 3.4329 - val_accuracy: 0.0000e+00 - 42ms/epoch - 42ms/step\n",
      "Epoch 132/200\n",
      "1/1 - 0s - loss: 0.1109 - accuracy: 1.0000 - val_loss: 4.4250 - val_accuracy: 0.0000e+00 - 41ms/epoch - 41ms/step\n",
      "Epoch 133/200\n",
      "1/1 - 0s - loss: 0.0709 - accuracy: 1.0000 - val_loss: 5.0985 - val_accuracy: 0.0000e+00 - 42ms/epoch - 42ms/step\n",
      "Epoch 134/200\n",
      "1/1 - 0s - loss: 0.0993 - accuracy: 1.0000 - val_loss: 5.4819 - val_accuracy: 0.0000e+00 - 41ms/epoch - 41ms/step\n",
      "Epoch 135/200\n",
      "1/1 - 0s - loss: 0.1076 - accuracy: 0.8889 - val_loss: 5.7127 - val_accuracy: 0.0000e+00 - 42ms/epoch - 42ms/step\n",
      "Epoch 136/200\n",
      "1/1 - 0s - loss: 0.1022 - accuracy: 1.0000 - val_loss: 5.8599 - val_accuracy: 0.0000e+00 - 41ms/epoch - 41ms/step\n",
      "Epoch 137/200\n",
      "1/1 - 0s - loss: 0.1068 - accuracy: 1.0000 - val_loss: 5.9105 - val_accuracy: 0.0000e+00 - 42ms/epoch - 42ms/step\n",
      "Epoch 138/200\n",
      "1/1 - 0s - loss: 0.1145 - accuracy: 0.8889 - val_loss: 5.9436 - val_accuracy: 0.0000e+00 - 40ms/epoch - 40ms/step\n",
      "Epoch 139/200\n",
      "1/1 - 0s - loss: 0.0860 - accuracy: 1.0000 - val_loss: 5.9647 - val_accuracy: 0.0000e+00 - 44ms/epoch - 44ms/step\n",
      "Epoch 140/200\n",
      "1/1 - 0s - loss: 0.1246 - accuracy: 0.8889 - val_loss: 5.9479 - val_accuracy: 0.0000e+00 - 41ms/epoch - 41ms/step\n",
      "Epoch 141/200\n",
      "1/1 - 0s - loss: 0.1097 - accuracy: 0.8889 - val_loss: 5.9349 - val_accuracy: 0.0000e+00 - 42ms/epoch - 42ms/step\n",
      "Epoch 142/200\n",
      "1/1 - 0s - loss: 0.0732 - accuracy: 1.0000 - val_loss: 5.9085 - val_accuracy: 0.0000e+00 - 41ms/epoch - 41ms/step\n",
      "Epoch 143/200\n",
      "1/1 - 0s - loss: 0.0749 - accuracy: 1.0000 - val_loss: 5.8891 - val_accuracy: 0.0000e+00 - 41ms/epoch - 41ms/step\n",
      "Epoch 144/200\n",
      "1/1 - 0s - loss: 0.0383 - accuracy: 1.0000 - val_loss: 5.8699 - val_accuracy: 0.0000e+00 - 40ms/epoch - 40ms/step\n",
      "Epoch 145/200\n",
      "1/1 - 0s - loss: 0.0673 - accuracy: 1.0000 - val_loss: 5.8437 - val_accuracy: 0.0000e+00 - 42ms/epoch - 42ms/step\n",
      "Epoch 146/200\n",
      "1/1 - 0s - loss: 0.3298 - accuracy: 0.7778 - val_loss: 5.8448 - val_accuracy: 0.0000e+00 - 40ms/epoch - 40ms/step\n",
      "Epoch 147/200\n",
      "1/1 - 0s - loss: 0.1716 - accuracy: 0.8889 - val_loss: 5.8603 - val_accuracy: 0.0000e+00 - 42ms/epoch - 42ms/step\n",
      "Epoch 148/200\n",
      "1/1 - 0s - loss: 0.0883 - accuracy: 1.0000 - val_loss: 5.8506 - val_accuracy: 0.0000e+00 - 42ms/epoch - 42ms/step\n",
      "Epoch 149/200\n",
      "1/1 - 0s - loss: 0.0581 - accuracy: 1.0000 - val_loss: 5.8316 - val_accuracy: 0.0000e+00 - 41ms/epoch - 41ms/step\n",
      "Epoch 150/200\n",
      "1/1 - 0s - loss: 0.1440 - accuracy: 0.8889 - val_loss: 5.8289 - val_accuracy: 0.0000e+00 - 45ms/epoch - 45ms/step\n",
      "Epoch 151/200\n",
      "1/1 - 0s - loss: 0.1161 - accuracy: 0.8889 - val_loss: 5.8444 - val_accuracy: 0.0000e+00 - 39ms/epoch - 39ms/step\n",
      "Epoch 152/200\n",
      "1/1 - 0s - loss: 0.1404 - accuracy: 1.0000 - val_loss: 5.8823 - val_accuracy: 0.0000e+00 - 41ms/epoch - 41ms/step\n",
      "Epoch 153/200\n",
      "1/1 - 0s - loss: 0.0562 - accuracy: 1.0000 - val_loss: 5.9229 - val_accuracy: 0.0000e+00 - 40ms/epoch - 40ms/step\n",
      "Epoch 154/200\n",
      "1/1 - 0s - loss: 0.0378 - accuracy: 1.0000 - val_loss: 5.9552 - val_accuracy: 0.0000e+00 - 41ms/epoch - 41ms/step\n",
      "Epoch 155/200\n",
      "1/1 - 0s - loss: 0.0571 - accuracy: 1.0000 - val_loss: 5.9806 - val_accuracy: 0.0000e+00 - 41ms/epoch - 41ms/step\n",
      "Epoch 156/200\n",
      "1/1 - 0s - loss: 0.0791 - accuracy: 1.0000 - val_loss: 5.9701 - val_accuracy: 0.0000e+00 - 40ms/epoch - 40ms/step\n",
      "Epoch 157/200\n",
      "1/1 - 0s - loss: 0.2928 - accuracy: 0.8889 - val_loss: 5.9429 - val_accuracy: 0.0000e+00 - 42ms/epoch - 42ms/step\n",
      "Epoch 158/200\n",
      "1/1 - 0s - loss: 0.1159 - accuracy: 1.0000 - val_loss: 5.8382 - val_accuracy: 0.0000e+00 - 40ms/epoch - 40ms/step\n",
      "Epoch 159/200\n",
      "1/1 - 0s - loss: 0.1979 - accuracy: 0.8889 - val_loss: 5.6691 - val_accuracy: 0.0000e+00 - 40ms/epoch - 40ms/step\n",
      "Epoch 160/200\n",
      "1/1 - 0s - loss: 0.0388 - accuracy: 1.0000 - val_loss: 5.4890 - val_accuracy: 0.0000e+00 - 43ms/epoch - 43ms/step\n",
      "Epoch 161/200\n",
      "1/1 - 0s - loss: 0.0610 - accuracy: 1.0000 - val_loss: 5.3128 - val_accuracy: 0.0000e+00 - 43ms/epoch - 43ms/step\n",
      "Epoch 162/200\n",
      "1/1 - 0s - loss: 0.1244 - accuracy: 0.8889 - val_loss: 5.2094 - val_accuracy: 0.0000e+00 - 40ms/epoch - 40ms/step\n",
      "Epoch 163/200\n",
      "1/1 - 0s - loss: 0.0592 - accuracy: 1.0000 - val_loss: 5.1313 - val_accuracy: 0.0000e+00 - 42ms/epoch - 42ms/step\n",
      "Epoch 164/200\n",
      "1/1 - 0s - loss: 0.0368 - accuracy: 1.0000 - val_loss: 5.0732 - val_accuracy: 0.0000e+00 - 45ms/epoch - 45ms/step\n",
      "Epoch 165/200\n",
      "1/1 - 0s - loss: 0.0661 - accuracy: 1.0000 - val_loss: 5.0857 - val_accuracy: 0.0000e+00 - 42ms/epoch - 42ms/step\n",
      "Epoch 166/200\n",
      "1/1 - 0s - loss: 0.0472 - accuracy: 1.0000 - val_loss: 5.1201 - val_accuracy: 0.0000e+00 - 41ms/epoch - 41ms/step\n",
      "Epoch 167/200\n",
      "1/1 - 0s - loss: 0.0367 - accuracy: 1.0000 - val_loss: 5.1573 - val_accuracy: 0.0000e+00 - 43ms/epoch - 43ms/step\n",
      "Epoch 168/200\n",
      "1/1 - 0s - loss: 0.2336 - accuracy: 0.8889 - val_loss: 5.1190 - val_accuracy: 0.0000e+00 - 43ms/epoch - 43ms/step\n",
      "Epoch 169/200\n",
      "1/1 - 0s - loss: 0.1793 - accuracy: 0.8889 - val_loss: 5.0182 - val_accuracy: 0.0000e+00 - 40ms/epoch - 40ms/step\n",
      "Epoch 170/200\n",
      "1/1 - 0s - loss: 0.0270 - accuracy: 1.0000 - val_loss: 4.8977 - val_accuracy: 0.0000e+00 - 42ms/epoch - 42ms/step\n",
      "Epoch 171/200\n",
      "1/1 - 0s - loss: 0.0411 - accuracy: 1.0000 - val_loss: 4.7476 - val_accuracy: 0.0000e+00 - 39ms/epoch - 39ms/step\n",
      "Epoch 172/200\n",
      "1/1 - 0s - loss: 0.1801 - accuracy: 0.8889 - val_loss: 4.3976 - val_accuracy: 0.0000e+00 - 41ms/epoch - 41ms/step\n",
      "Epoch 173/200\n",
      "1/1 - 0s - loss: 0.0414 - accuracy: 1.0000 - val_loss: 4.0470 - val_accuracy: 0.0000e+00 - 39ms/epoch - 39ms/step\n",
      "Epoch 174/200\n",
      "1/1 - 0s - loss: 0.0879 - accuracy: 1.0000 - val_loss: 3.8718 - val_accuracy: 0.0000e+00 - 42ms/epoch - 42ms/step\n",
      "Epoch 175/200\n",
      "1/1 - 0s - loss: 0.0861 - accuracy: 1.0000 - val_loss: 3.8121 - val_accuracy: 0.0000e+00 - 39ms/epoch - 39ms/step\n",
      "Epoch 176/200\n",
      "1/1 - 0s - loss: 0.0832 - accuracy: 1.0000 - val_loss: 3.8627 - val_accuracy: 0.0000e+00 - 41ms/epoch - 41ms/step\n",
      "Epoch 177/200\n",
      "1/1 - 0s - loss: 0.1016 - accuracy: 0.8889 - val_loss: 4.0139 - val_accuracy: 0.0000e+00 - 40ms/epoch - 40ms/step\n",
      "Epoch 178/200\n",
      "1/1 - 0s - loss: 0.1156 - accuracy: 0.8889 - val_loss: 4.0444 - val_accuracy: 0.0000e+00 - 40ms/epoch - 40ms/step\n",
      "Epoch 179/200\n",
      "1/1 - 0s - loss: 0.0265 - accuracy: 1.0000 - val_loss: 4.0947 - val_accuracy: 0.0000e+00 - 41ms/epoch - 41ms/step\n",
      "Epoch 180/200\n",
      "1/1 - 0s - loss: 0.0649 - accuracy: 1.0000 - val_loss: 4.2451 - val_accuracy: 0.0000e+00 - 42ms/epoch - 42ms/step\n",
      "Epoch 181/200\n",
      "1/1 - 0s - loss: 0.1110 - accuracy: 0.8889 - val_loss: 4.2981 - val_accuracy: 0.0000e+00 - 41ms/epoch - 41ms/step\n",
      "Epoch 182/200\n",
      "1/1 - 0s - loss: 0.1160 - accuracy: 1.0000 - val_loss: 4.1468 - val_accuracy: 0.0000e+00 - 40ms/epoch - 40ms/step\n",
      "Epoch 183/200\n",
      "1/1 - 0s - loss: 0.0220 - accuracy: 1.0000 - val_loss: 4.0242 - val_accuracy: 0.0000e+00 - 41ms/epoch - 41ms/step\n",
      "Epoch 184/200\n",
      "1/1 - 0s - loss: 0.0187 - accuracy: 1.0000 - val_loss: 3.9159 - val_accuracy: 0.0000e+00 - 41ms/epoch - 41ms/step\n",
      "Epoch 185/200\n",
      "1/1 - 0s - loss: 0.1079 - accuracy: 0.8889 - val_loss: 4.0639 - val_accuracy: 0.0000e+00 - 40ms/epoch - 40ms/step\n",
      "Epoch 186/200\n",
      "1/1 - 0s - loss: 0.0201 - accuracy: 1.0000 - val_loss: 4.2191 - val_accuracy: 0.0000e+00 - 43ms/epoch - 43ms/step\n",
      "Epoch 187/200\n",
      "1/1 - 0s - loss: 0.2535 - accuracy: 0.8889 - val_loss: 4.2485 - val_accuracy: 0.0000e+00 - 40ms/epoch - 40ms/step\n",
      "Epoch 188/200\n",
      "1/1 - 0s - loss: 0.0162 - accuracy: 1.0000 - val_loss: 4.2725 - val_accuracy: 0.0000e+00 - 43ms/epoch - 43ms/step\n",
      "Epoch 189/200\n",
      "1/1 - 0s - loss: 0.1672 - accuracy: 0.8889 - val_loss: 4.1436 - val_accuracy: 0.0000e+00 - 40ms/epoch - 40ms/step\n",
      "Epoch 190/200\n",
      "1/1 - 0s - loss: 0.0284 - accuracy: 1.0000 - val_loss: 3.9856 - val_accuracy: 0.0000e+00 - 41ms/epoch - 41ms/step\n",
      "Epoch 191/200\n",
      "1/1 - 0s - loss: 0.1710 - accuracy: 0.8889 - val_loss: 3.7619 - val_accuracy: 0.0000e+00 - 40ms/epoch - 40ms/step\n",
      "Epoch 192/200\n",
      "1/1 - 0s - loss: 0.0428 - accuracy: 1.0000 - val_loss: 3.5909 - val_accuracy: 0.0000e+00 - 44ms/epoch - 44ms/step\n",
      "Epoch 193/200\n",
      "1/1 - 0s - loss: 0.0329 - accuracy: 1.0000 - val_loss: 3.4544 - val_accuracy: 0.0000e+00 - 40ms/epoch - 40ms/step\n",
      "Epoch 194/200\n",
      "1/1 - 0s - loss: 0.3010 - accuracy: 0.8889 - val_loss: 3.4385 - val_accuracy: 0.0000e+00 - 41ms/epoch - 41ms/step\n",
      "Epoch 195/200\n",
      "1/1 - 0s - loss: 0.0806 - accuracy: 1.0000 - val_loss: 3.4785 - val_accuracy: 0.0000e+00 - 45ms/epoch - 45ms/step\n",
      "Epoch 196/200\n",
      "1/1 - 0s - loss: 0.0568 - accuracy: 1.0000 - val_loss: 3.5458 - val_accuracy: 0.0000e+00 - 42ms/epoch - 42ms/step\n",
      "Epoch 197/200\n",
      "1/1 - 0s - loss: 0.2303 - accuracy: 0.8889 - val_loss: 3.7359 - val_accuracy: 0.0000e+00 - 39ms/epoch - 39ms/step\n",
      "Epoch 198/200\n",
      "1/1 - 0s - loss: 0.0434 - accuracy: 1.0000 - val_loss: 3.9153 - val_accuracy: 0.0000e+00 - 42ms/epoch - 42ms/step\n",
      "Epoch 199/200\n",
      "1/1 - 0s - loss: 0.0463 - accuracy: 1.0000 - val_loss: 4.0968 - val_accuracy: 0.0000e+00 - 39ms/epoch - 39ms/step\n",
      "Epoch 200/200\n",
      "1/1 - 0s - loss: 0.1269 - accuracy: 0.8889 - val_loss: 4.1321 - val_accuracy: 0.0000e+00 - 40ms/epoch - 40ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x276061ccd00>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rnn.fit(train_data,train_labels,validation_data=(val_data,val_labels),batch_size=64,epochs=200,verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f28b946a23085e562808fe655c9ec93beea4426c1b8daeb4e80eba8c1a3d75c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
