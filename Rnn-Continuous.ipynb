{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.utils as utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "import ta \n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "csvFileAddress = 'csv/FTSE100_H1_201607071400_202206242200.csv'\n",
    "\n",
    "DJ = pd.read_csv(csvFileAddress,delim_whitespace=True)\n",
    "\n",
    "DJ['<ISGREEN>'] =  DJ['<CLOSE>'] > DJ['<OPEN>']\n",
    "DJ['<SIZE>'] =  (DJ['<CLOSE>'] - DJ['<OPEN>']) / DJ['<CLOSE>'] *100\n",
    "DJ['<VOLATILITY>'] =  DJ['<HIGH>'] - DJ['<LOW>'] /DJ['<CLOSE>']\n",
    "\n",
    "DJ.drop(['<VOL>'],axis=1,inplace=True)\n",
    "\n",
    "DJ.fillna(0,inplace=True)\n",
    "\n",
    "DJ['<EMA30>']= ta.trend.ema_indicator( DJ['<CLOSE>'],window=30)\n",
    "DJ['<EMA50>']= ta.trend.ema_indicator( DJ['<CLOSE>'],window=50)\n",
    "DJ['<EMA200>']= ta.trend.ema_indicator( DJ['<CLOSE>'],window=200)\n",
    "\n",
    "def Upper(e):\n",
    "    if e['<ISGREEN>'] : \n",
    "        return e['<HIGH>']-e['<CLOSE>']\n",
    "    return e['<HIGH>']-e['<OPEN>']\n",
    "\n",
    "def Lower(e):\n",
    "    if e['<ISGREEN>'] : \n",
    "        return e['<OPEN>']-e['<LOW>']\n",
    "    return e['<CLOSE>']-e['<LOW>']\n",
    "\n",
    "\n",
    "DJ['<UPPER>'] = DJ.apply(Upper,axis=1)\n",
    "DJ['<LOWER>'] = DJ.apply(Lower,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Adding TA indicators : \n",
    "\n",
    "from ta.volatility import BollingerBands,KeltnerChannel,average_true_range\n",
    "from ta.trend import MACD\n",
    "\n",
    "DJ['<RSI>'] = ta.momentum.rsi(DJ['<CLOSE>'],window=15,fillna=1) / 100\n",
    "# DJ['<CCI>'] = ta.trend.cci(close=DJ['<CLOSE>'],high=DJ['<HIGH>'],low=DJ['<LOW>'],window=14,fillna=1)\n",
    "\n",
    "\n",
    "keltner = KeltnerChannel(close=DJ['<CLOSE>'],high=DJ['<HIGH>'],low=DJ['<LOW>'],window=50,window_atr=20,multiplier=3,fillna=1)\n",
    "DJ['<KELTNER_H>'] = keltner.keltner_channel_hband()\n",
    "DJ['<KELTNER_L>'] = keltner.keltner_channel_lband()\n",
    "DJ['<KELTNER_M>'] = keltner.keltner_channel_mband()\n",
    "\n",
    "DJ['<KELT_L_IND>'] = keltner.keltner_channel_lband_indicator()\n",
    "DJ['<KELT_H_IND>'] = keltner.keltner_channel_hband_indicator()\n",
    "\n",
    "\n",
    "\n",
    "bollinger =BollingerBands(close=DJ['<CLOSE>'],window=50,window_dev=3,fillna=True)\n",
    "DJ['<BOL_H_IND>']=bollinger.bollinger_hband_indicator()\n",
    "DJ['<BOL_L_IND>']=bollinger.bollinger_lband_indicator()\n",
    "\n",
    "# macd = MACD(DJ['<CLOSE>'],fillna=True)\n",
    "\n",
    "\n",
    "DJ['<ATR_24>'] = average_true_range(close=DJ['<CLOSE>'],high=DJ['<HIGH>'],low=DJ['<LOW>'],window=30).apply(lambda e : e/100)\n",
    "DJ['<ATR_24_MULT>'] =abs(DJ['<SIZE>']) / DJ['<ATR_24>'] \n",
    "\n",
    "\n",
    "DJ[\"<ISGREEN>\"] = DJ[\"<ISGREEN>\"].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeFrame = (int(DJ.iloc[1][1][1])-int(DJ.iloc[0][1][1]) ) * 60 + (int(DJ.iloc[1][1][3:5])-int(DJ.iloc[0][1][3:5]))\n",
    "CandlesInDay = 24 * (60//timeFrame)\n",
    "timeFrame\n",
    "def candleToTime(j):\n",
    "    minuteMult = CandlesInDay//24\n",
    "    k=j//minuteMult\n",
    "    sth=timeFrame*(j%minuteMult)\n",
    "    return '{:02d}:{:02d}:00'.format(k,sth)\n",
    "\n",
    "uniqueDays = DJ.drop_duplicates(subset='<DATE>')\n",
    "uniqueDays = pd.DataFrame(uniqueDays)\n",
    "\n",
    "uniqueDaysCount=uniqueDays.shape[0]\n",
    "\n",
    "newnumparr = np.full((uniqueDaysCount*CandlesInDay,2),'',dtype=np.object_)\n",
    "\n",
    "\n",
    "for i in range(uniqueDaysCount):\n",
    "    for j in range(CandlesInDay):\n",
    "        newnumparr[(i*CandlesInDay)+j]=[uniqueDays.iloc[i][0],candleToTime(j)]\n",
    "\n",
    "newDF = pd.DataFrame(newnumparr,columns=['<DATE>','<TIME>'])\n",
    "\n",
    "newestDF = newDF.merge(DJ,on=['<DATE>','<TIME>'],how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "newestDF.drop(range(CandlesInDay),inplace=True)\n",
    "newestDF.fillna(0.0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;OPEN&gt;</th>\n",
       "      <th>&lt;HIGH&gt;</th>\n",
       "      <th>&lt;LOW&gt;</th>\n",
       "      <th>&lt;CLOSE&gt;</th>\n",
       "      <th>&lt;TICKVOL&gt;</th>\n",
       "      <th>&lt;SPREAD&gt;</th>\n",
       "      <th>&lt;ISGREEN&gt;</th>\n",
       "      <th>&lt;SIZE&gt;</th>\n",
       "      <th>&lt;VOLATILITY&gt;</th>\n",
       "      <th>&lt;EMA30&gt;</th>\n",
       "      <th>...</th>\n",
       "      <th>&lt;RSI&gt;</th>\n",
       "      <th>&lt;KELTNER_H&gt;</th>\n",
       "      <th>&lt;KELTNER_L&gt;</th>\n",
       "      <th>&lt;KELTNER_M&gt;</th>\n",
       "      <th>&lt;KELT_L_IND&gt;</th>\n",
       "      <th>&lt;KELT_H_IND&gt;</th>\n",
       "      <th>&lt;BOL_H_IND&gt;</th>\n",
       "      <th>&lt;BOL_L_IND&gt;</th>\n",
       "      <th>&lt;ATR_24&gt;</th>\n",
       "      <th>&lt;ATR_24_MULT&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36120.000000</td>\n",
       "      <td>36120.000000</td>\n",
       "      <td>36120.000000</td>\n",
       "      <td>36120.000000</td>\n",
       "      <td>36120.000000</td>\n",
       "      <td>36120.000000</td>\n",
       "      <td>36120.000000</td>\n",
       "      <td>36120.000000</td>\n",
       "      <td>36120.000000</td>\n",
       "      <td>36120.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>36120.000000</td>\n",
       "      <td>36120.000000</td>\n",
       "      <td>36120.000000</td>\n",
       "      <td>36120.000000</td>\n",
       "      <td>36120.000000</td>\n",
       "      <td>36120.000000</td>\n",
       "      <td>36120.000000</td>\n",
       "      <td>36120.000000</td>\n",
       "      <td>36120.000000</td>\n",
       "      <td>3.612000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5434.366548</td>\n",
       "      <td>5442.025133</td>\n",
       "      <td>5426.499352</td>\n",
       "      <td>5434.406459</td>\n",
       "      <td>2155.695792</td>\n",
       "      <td>9.354623</td>\n",
       "      <td>0.387846</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>5441.253644</td>\n",
       "      <td>5430.729255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393162</td>\n",
       "      <td>5449.448188</td>\n",
       "      <td>5418.405211</td>\n",
       "      <td>5433.926700</td>\n",
       "      <td>0.241667</td>\n",
       "      <td>0.304679</td>\n",
       "      <td>0.004568</td>\n",
       "      <td>0.006755</td>\n",
       "      <td>0.159228</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2984.705515</td>\n",
       "      <td>2988.431832</td>\n",
       "      <td>2980.868389</td>\n",
       "      <td>2984.718278</td>\n",
       "      <td>2576.079910</td>\n",
       "      <td>18.641429</td>\n",
       "      <td>0.487266</td>\n",
       "      <td>0.211993</td>\n",
       "      <td>2988.018345</td>\n",
       "      <td>2986.861435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236571</td>\n",
       "      <td>2991.825541</td>\n",
       "      <td>2976.664279</td>\n",
       "      <td>2984.227960</td>\n",
       "      <td>0.428099</td>\n",
       "      <td>0.460278</td>\n",
       "      <td>0.067434</td>\n",
       "      <td>0.081913</td>\n",
       "      <td>0.128594</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.963926</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5793.775000</td>\n",
       "      <td>5808.675000</td>\n",
       "      <td>5778.300000</td>\n",
       "      <td>5794.100000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.055761</td>\n",
       "      <td>5807.675518</td>\n",
       "      <td>5792.193296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274279</td>\n",
       "      <td>5824.347167</td>\n",
       "      <td>5768.463000</td>\n",
       "      <td>5795.573000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112784</td>\n",
       "      <td>2.443579e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7021.800000</td>\n",
       "      <td>7031.100000</td>\n",
       "      <td>7011.050000</td>\n",
       "      <td>7021.700000</td>\n",
       "      <td>1266.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7030.102547</td>\n",
       "      <td>7024.749259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469437</td>\n",
       "      <td>7044.560000</td>\n",
       "      <td>7003.930000</td>\n",
       "      <td>7025.742667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.162774</td>\n",
       "      <td>3.348140e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7346.225000</td>\n",
       "      <td>7354.400000</td>\n",
       "      <td>7337.800000</td>\n",
       "      <td>7346.100000</td>\n",
       "      <td>3191.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.063498</td>\n",
       "      <td>7353.400681</td>\n",
       "      <td>7346.161466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.565531</td>\n",
       "      <td>7362.504833</td>\n",
       "      <td>7328.775667</td>\n",
       "      <td>7345.881000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.208091</td>\n",
       "      <td>7.909651e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7899.400000</td>\n",
       "      <td>7909.400000</td>\n",
       "      <td>7889.900000</td>\n",
       "      <td>7899.400000</td>\n",
       "      <td>22862.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.536502</td>\n",
       "      <td>7908.401052</td>\n",
       "      <td>7858.856449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.875402</td>\n",
       "      <td>7856.245333</td>\n",
       "      <td>7823.671333</td>\n",
       "      <td>7839.821333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.248644</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             <OPEN>        <HIGH>         <LOW>       <CLOSE>     <TICKVOL>  \\\n",
       "count  36120.000000  36120.000000  36120.000000  36120.000000  36120.000000   \n",
       "mean    5434.366548   5442.025133   5426.499352   5434.406459   2155.695792   \n",
       "std     2984.705515   2988.431832   2980.868389   2984.718278   2576.079910   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%     5793.775000   5808.675000   5778.300000   5794.100000    143.000000   \n",
       "50%     7021.800000   7031.100000   7011.050000   7021.700000   1266.000000   \n",
       "75%     7346.225000   7354.400000   7337.800000   7346.100000   3191.000000   \n",
       "max     7899.400000   7909.400000   7889.900000   7899.400000  22862.000000   \n",
       "\n",
       "           <SPREAD>     <ISGREEN>        <SIZE>  <VOLATILITY>       <EMA30>  \\\n",
       "count  36120.000000  36120.000000  36120.000000  36120.000000  36120.000000   \n",
       "mean       9.354623      0.387846      0.000415   5441.253644   5430.729255   \n",
       "std       18.641429      0.487266      0.211993   2988.018345   2986.861435   \n",
       "min        0.000000      0.000000     -4.963926      0.000000      0.000000   \n",
       "25%        0.000000      0.000000     -0.055761   5807.675518   5792.193296   \n",
       "50%        4.000000      0.000000      0.000000   7030.102547   7024.749259   \n",
       "75%        9.000000      1.000000      0.063498   7353.400681   7346.161466   \n",
       "max      112.000000      1.000000      3.536502   7908.401052   7858.856449   \n",
       "\n",
       "       ...         <RSI>   <KELTNER_H>   <KELTNER_L>   <KELTNER_M>  \\\n",
       "count  ...  36120.000000  36120.000000  36120.000000  36120.000000   \n",
       "mean   ...      0.393162   5449.448188   5418.405211   5433.926700   \n",
       "std    ...      0.236571   2991.825541   2976.664279   2984.227960   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.274279   5824.347167   5768.463000   5795.573000   \n",
       "50%    ...      0.469437   7044.560000   7003.930000   7025.742667   \n",
       "75%    ...      0.565531   7362.504833   7328.775667   7345.881000   \n",
       "max    ...      0.875402   7856.245333   7823.671333   7839.821333   \n",
       "\n",
       "       <KELT_L_IND>  <KELT_H_IND>   <BOL_H_IND>   <BOL_L_IND>      <ATR_24>  \\\n",
       "count  36120.000000  36120.000000  36120.000000  36120.000000  36120.000000   \n",
       "mean       0.241667      0.304679      0.004568      0.006755      0.159228   \n",
       "std        0.428099      0.460278      0.067434      0.081913      0.128594   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.112784   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.162774   \n",
       "75%        0.000000      1.000000      0.000000      0.000000      0.208091   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.248644   \n",
       "\n",
       "       <ATR_24_MULT>  \n",
       "count   3.612000e+04  \n",
       "mean             inf  \n",
       "std              NaN  \n",
       "min     0.000000e+00  \n",
       "25%     2.443579e-02  \n",
       "50%     3.348140e-01  \n",
       "75%     7.909651e-01  \n",
       "max              inf  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newestDF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;DATE&gt;</th>\n",
       "      <th>&lt;TIME&gt;</th>\n",
       "      <th>&lt;OPEN&gt;</th>\n",
       "      <th>&lt;HIGH&gt;</th>\n",
       "      <th>&lt;LOW&gt;</th>\n",
       "      <th>&lt;CLOSE&gt;</th>\n",
       "      <th>&lt;TICKVOL&gt;</th>\n",
       "      <th>&lt;SPREAD&gt;</th>\n",
       "      <th>&lt;ISGREEN&gt;</th>\n",
       "      <th>&lt;SIZE&gt;</th>\n",
       "      <th>...</th>\n",
       "      <th>&lt;RSI&gt;</th>\n",
       "      <th>&lt;KELTNER_H&gt;</th>\n",
       "      <th>&lt;KELTNER_L&gt;</th>\n",
       "      <th>&lt;KELTNER_M&gt;</th>\n",
       "      <th>&lt;KELT_L_IND&gt;</th>\n",
       "      <th>&lt;KELT_H_IND&gt;</th>\n",
       "      <th>&lt;BOL_H_IND&gt;</th>\n",
       "      <th>&lt;BOL_L_IND&gt;</th>\n",
       "      <th>&lt;ATR_24&gt;</th>\n",
       "      <th>&lt;ATR_24_MULT&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2016.07.08</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>6537.8</td>\n",
       "      <td>6537.8</td>\n",
       "      <td>6528.9</td>\n",
       "      <td>6528.9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.136317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438245</td>\n",
       "      <td>6558.906061</td>\n",
       "      <td>6521.887879</td>\n",
       "      <td>6540.396970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2016.07.08</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>6538.4</td>\n",
       "      <td>6538.9</td>\n",
       "      <td>6523.9</td>\n",
       "      <td>6527.4</td>\n",
       "      <td>249.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.168520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430342</td>\n",
       "      <td>6557.752778</td>\n",
       "      <td>6521.319444</td>\n",
       "      <td>6539.536111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2016.07.08</td>\n",
       "      <td>02:00:00</td>\n",
       "      <td>6527.9</td>\n",
       "      <td>6530.4</td>\n",
       "      <td>6526.6</td>\n",
       "      <td>6526.9</td>\n",
       "      <td>242.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.015321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.427588</td>\n",
       "      <td>6555.753846</td>\n",
       "      <td>6521.538462</td>\n",
       "      <td>6538.646154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2016.07.08</td>\n",
       "      <td>03:00:00</td>\n",
       "      <td>6527.1</td>\n",
       "      <td>6549.6</td>\n",
       "      <td>6522.5</td>\n",
       "      <td>6544.6</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.267396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.539393</td>\n",
       "      <td>6556.485714</td>\n",
       "      <td>6520.842857</td>\n",
       "      <td>6538.664286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2016.07.08</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>6544.6</td>\n",
       "      <td>6546.6</td>\n",
       "      <td>6538.1</td>\n",
       "      <td>6545.1</td>\n",
       "      <td>1778.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.542100</td>\n",
       "      <td>6556.171111</td>\n",
       "      <td>6521.771111</td>\n",
       "      <td>6538.971111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2016.07.08</td>\n",
       "      <td>05:00:00</td>\n",
       "      <td>6545.1</td>\n",
       "      <td>6545.1</td>\n",
       "      <td>6528.1</td>\n",
       "      <td>6534.6</td>\n",
       "      <td>1429.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.160683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.478789</td>\n",
       "      <td>6555.968750</td>\n",
       "      <td>6521.593750</td>\n",
       "      <td>6538.781250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2016.07.08</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>6534.6</td>\n",
       "      <td>6537.1</td>\n",
       "      <td>6519.6</td>\n",
       "      <td>6522.1</td>\n",
       "      <td>1394.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.191656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.416713</td>\n",
       "      <td>6555.250980</td>\n",
       "      <td>6520.839216</td>\n",
       "      <td>6538.045098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2016.07.08</td>\n",
       "      <td>07:00:00</td>\n",
       "      <td>6522.1</td>\n",
       "      <td>6526.6</td>\n",
       "      <td>6519.6</td>\n",
       "      <td>6524.6</td>\n",
       "      <td>1137.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.038317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.432480</td>\n",
       "      <td>6553.881481</td>\n",
       "      <td>6520.603704</td>\n",
       "      <td>6537.242593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2016.07.08</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>6524.6</td>\n",
       "      <td>6531.1</td>\n",
       "      <td>6524.1</td>\n",
       "      <td>6529.6</td>\n",
       "      <td>1441.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.076574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463554</td>\n",
       "      <td>6552.901754</td>\n",
       "      <td>6520.638596</td>\n",
       "      <td>6536.770175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2016.07.08</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>6529.6</td>\n",
       "      <td>6537.6</td>\n",
       "      <td>6524.1</td>\n",
       "      <td>6531.6</td>\n",
       "      <td>2106.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.030620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475853</td>\n",
       "      <td>6552.486667</td>\n",
       "      <td>6520.486667</td>\n",
       "      <td>6536.486667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        <DATE>    <TIME>  <OPEN>  <HIGH>   <LOW>  <CLOSE>  <TICKVOL>  \\\n",
       "24  2016.07.08  00:00:00  6537.8  6537.8  6528.9   6528.9        6.0   \n",
       "25  2016.07.08  01:00:00  6538.4  6538.9  6523.9   6527.4      249.0   \n",
       "26  2016.07.08  02:00:00  6527.9  6530.4  6526.6   6526.9      242.0   \n",
       "27  2016.07.08  03:00:00  6527.1  6549.6  6522.5   6544.6     1327.0   \n",
       "28  2016.07.08  04:00:00  6544.6  6546.6  6538.1   6545.1     1778.0   \n",
       "29  2016.07.08  05:00:00  6545.1  6545.1  6528.1   6534.6     1429.0   \n",
       "30  2016.07.08  06:00:00  6534.6  6537.1  6519.6   6522.1     1394.0   \n",
       "31  2016.07.08  07:00:00  6522.1  6526.6  6519.6   6524.6     1137.0   \n",
       "32  2016.07.08  08:00:00  6524.6  6531.1  6524.1   6529.6     1441.0   \n",
       "33  2016.07.08  09:00:00  6529.6  6537.6  6524.1   6531.6     2106.0   \n",
       "\n",
       "    <SPREAD>  <ISGREEN>    <SIZE>  ...     <RSI>  <KELTNER_H>  <KELTNER_L>  \\\n",
       "24     110.0        0.0 -0.136317  ...  0.438245  6558.906061  6521.887879   \n",
       "25     107.0        0.0 -0.168520  ...  0.430342  6557.752778  6521.319444   \n",
       "26     110.0        0.0 -0.015321  ...  0.427588  6555.753846  6521.538462   \n",
       "27       8.0        1.0  0.267396  ...  0.539393  6556.485714  6520.842857   \n",
       "28       8.0        1.0  0.007639  ...  0.542100  6556.171111  6521.771111   \n",
       "29       7.0        0.0 -0.160683  ...  0.478789  6555.968750  6521.593750   \n",
       "30       8.0        0.0 -0.191656  ...  0.416713  6555.250980  6520.839216   \n",
       "31       8.0        1.0  0.038317  ...  0.432480  6553.881481  6520.603704   \n",
       "32       8.0        1.0  0.076574  ...  0.463554  6552.901754  6520.638596   \n",
       "33       7.0        1.0  0.030620  ...  0.475853  6552.486667  6520.486667   \n",
       "\n",
       "    <KELTNER_M>  <KELT_L_IND>  <KELT_H_IND>  <BOL_H_IND>  <BOL_L_IND>  \\\n",
       "24  6540.396970           0.0           0.0          0.0          0.0   \n",
       "25  6539.536111           0.0           0.0          0.0          0.0   \n",
       "26  6538.646154           0.0           0.0          0.0          0.0   \n",
       "27  6538.664286           0.0           0.0          0.0          0.0   \n",
       "28  6538.971111           0.0           0.0          0.0          0.0   \n",
       "29  6538.781250           0.0           0.0          0.0          0.0   \n",
       "30  6538.045098           0.0           0.0          0.0          0.0   \n",
       "31  6537.242593           0.0           0.0          0.0          0.0   \n",
       "32  6536.770175           0.0           0.0          0.0          0.0   \n",
       "33  6536.486667           0.0           0.0          0.0          0.0   \n",
       "\n",
       "    <ATR_24>  <ATR_24_MULT>  \n",
       "24       0.0            inf  \n",
       "25       0.0            inf  \n",
       "26       0.0            inf  \n",
       "27       0.0            inf  \n",
       "28       0.0            inf  \n",
       "29       0.0            inf  \n",
       "30       0.0            inf  \n",
       "31       0.0            inf  \n",
       "32       0.0            inf  \n",
       "33       0.0            inf  \n",
       "\n",
       "[10 rows x 26 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newestDF.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import multiprocessing\n",
    "import mp\n",
    "\n",
    "\n",
    "df = newestDF.drop(['<DATE>','<TIME>'],axis=1)\n",
    "threadCount = 2\n",
    "\n",
    "trainNps=[]\n",
    "labelValues = []\n",
    "\n",
    "for i in range(threadCount): trainNps.append([])\n",
    "for i in range(threadCount): labelValues.append([])\n",
    "\n",
    "maxValues = df.max()\n",
    "\n",
    "lenDFthread =  len(df) / threadCount\n",
    "threads = []\n",
    "p = multiprocessing.Pool(threadCount)\n",
    "out=p.starmap(mp.thread_function,[(df.iloc[int(index*lenDFthread):int((1+index)*lenDFthread-1)],index,CandlesInDay) for index in range(threadCount)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 8272)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(out,dtype=np.object_).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas=[]\n",
    "labs=[]\n",
    "for i in range(threadCount): \n",
    "    datas = datas+out[i][0]\n",
    "    labs = labs + out[i][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16544, 16544)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datas),len(labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12408, 12408)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "l = len(datas)\n",
    "windows2= np.array(datas)\n",
    "\n",
    "labs = np.array(labs)\n",
    "\n",
    "\n",
    "train_data = windows2[:int(l*.75)]\n",
    "val_data = windows2[int(l*.75)+1:]\n",
    "\n",
    "\n",
    "\n",
    "train_labels = labs[:int(l*.75)].astype(np.uint8)\n",
    "val_labels = labs[int(l*.75)+1:].astype(np.uint8)\n",
    "\n",
    "\n",
    "len(train_data),len(train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4135, 4135)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_data),len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "signal\n",
       "2         0.557785\n",
       "1         0.222679\n",
       "0         0.219536\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(labs,columns=['signal']).value_counts()/len(labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 3, 32)             4992      \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 3, 64)             24832     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 128)               98816     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               12900     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 303       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 141,843\n",
      "Trainable params: 141,843\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D,LSTM, ConvLSTM1D,Flatten,SimpleRNN,GRU,AveragePooling2D\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model_rnn = keras.Sequential([\n",
    "    LSTM(32,input_shape=train_data[0].shape,dropout=.1,return_sequences=1),\n",
    "    LSTM(64,dropout=.1,return_sequences=1),\n",
    "    LSTM(128,dropout=.1,return_sequences=0),\n",
    "    # Flatten(),\n",
    "    Dense(100,activation='relu'),\n",
    "    Dense(3,activation='sigmoid'),\n",
    "\n",
    "])\n",
    "\n",
    "model_rnn.compile(\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer = 'adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "194/194 - 11s - loss: 1.0727 - accuracy: 0.5136 - val_loss: 0.9998 - val_accuracy: 0.6832 - 11s/epoch - 59ms/step\n",
      "Epoch 2/200\n",
      "194/194 - 5s - loss: 1.0423 - accuracy: 0.5160 - val_loss: 0.9474 - val_accuracy: 0.6832 - 5s/epoch - 28ms/step\n",
      "Epoch 3/200\n",
      "194/194 - 6s - loss: 1.0318 - accuracy: 0.5160 - val_loss: 0.9216 - val_accuracy: 0.6832 - 6s/epoch - 33ms/step\n",
      "Epoch 4/200\n",
      "194/194 - 4s - loss: 1.0289 - accuracy: 0.5160 - val_loss: 0.9105 - val_accuracy: 0.6832 - 4s/epoch - 20ms/step\n",
      "Epoch 5/200\n",
      "194/194 - 4s - loss: 1.0283 - accuracy: 0.5160 - val_loss: 0.9049 - val_accuracy: 0.6832 - 4s/epoch - 20ms/step\n",
      "Epoch 6/200\n",
      "194/194 - 4s - loss: 1.0282 - accuracy: 0.5160 - val_loss: 0.9020 - val_accuracy: 0.6832 - 4s/epoch - 20ms/step\n",
      "Epoch 7/200\n",
      "194/194 - 4s - loss: 1.0282 - accuracy: 0.5160 - val_loss: 0.9022 - val_accuracy: 0.6832 - 4s/epoch - 20ms/step\n",
      "Epoch 8/200\n",
      "194/194 - 4s - loss: 1.0282 - accuracy: 0.5160 - val_loss: 0.9016 - val_accuracy: 0.6832 - 4s/epoch - 20ms/step\n",
      "Epoch 9/200\n",
      "194/194 - 4s - loss: 1.0282 - accuracy: 0.5160 - val_loss: 0.9008 - val_accuracy: 0.6832 - 4s/epoch - 20ms/step\n",
      "Epoch 10/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/alint/Desktop/Markets-Data-ML/Rnn-Continuous.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/alint/Desktop/Markets-Data-ML/Rnn-Continuous.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model_rnn\u001b[39m.\u001b[39;49mfit(train_data,train_labels,validation_data\u001b[39m=\u001b[39;49m(val_data,val_labels),batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m,epochs\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m,verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py:1445\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1431\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_eval_data_handler\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1432\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39mget_data_handler(\n\u001b[1;32m   1433\u001b[0m       x\u001b[39m=\u001b[39mval_x,\n\u001b[1;32m   1434\u001b[0m       y\u001b[39m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1443\u001b[0m       model\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m,\n\u001b[1;32m   1444\u001b[0m       steps_per_execution\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution)\n\u001b[0;32m-> 1445\u001b[0m val_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(\n\u001b[1;32m   1446\u001b[0m     x\u001b[39m=\u001b[39;49mval_x,\n\u001b[1;32m   1447\u001b[0m     y\u001b[39m=\u001b[39;49mval_y,\n\u001b[1;32m   1448\u001b[0m     sample_weight\u001b[39m=\u001b[39;49mval_sample_weight,\n\u001b[1;32m   1449\u001b[0m     batch_size\u001b[39m=\u001b[39;49mvalidation_batch_size \u001b[39mor\u001b[39;49;00m batch_size,\n\u001b[1;32m   1450\u001b[0m     steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m   1451\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1452\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   1453\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   1454\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   1455\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1456\u001b[0m     _use_cached_eval_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   1457\u001b[0m val_logs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m   1458\u001b[0m epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py:1756\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1754\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m, step_num\u001b[39m=\u001b[39mstep, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1755\u001b[0m   callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 1756\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_function(iterator)\n\u001b[1;32m   1757\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1758\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    952\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 954\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateful_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    955\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    956\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    957\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_rnn.fit(train_data,train_labels,validation_data=(val_data,val_labels),batch_size=64,epochs=200,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Jun  1 2022, 06:34:44) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ee3717197db56dab91ad083a26bef10706ce761f0ab8e349ac843a6f8d1f4192"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
